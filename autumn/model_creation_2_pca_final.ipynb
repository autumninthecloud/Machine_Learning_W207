{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk\n",
    "# import xlsxwriter\n",
    "import openpyxl\n",
    "import os.path\n",
    "from os.path import exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
       "0          0      1        0      0          0     0     0           63  \n",
       "1          0      0        0      0          0     0     0           42  \n",
       "2          0      0        0      1          1     0     0           28  \n",
       "3          0      0        0      0          0     0     0           15  \n",
       "4          0      1        0      0          0     0     0           72  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"../data/train.csv\")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.027643</td>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.861582</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.129338</td>\n",
       "      <td>0.049637</td>\n",
       "      <td>0.166263</td>\n",
       "      <td>0.172014</td>\n",
       "      <td>0.061239</td>\n",
       "      <td>0.070420</td>\n",
       "      <td>38.039044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.163957</td>\n",
       "      <td>0.419175</td>\n",
       "      <td>0.294668</td>\n",
       "      <td>0.345356</td>\n",
       "      <td>0.099444</td>\n",
       "      <td>0.251409</td>\n",
       "      <td>0.335591</td>\n",
       "      <td>0.217204</td>\n",
       "      <td>0.372335</td>\n",
       "      <td>0.377411</td>\n",
       "      <td>0.239780</td>\n",
       "      <td>0.255866</td>\n",
       "      <td>20.591990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subject Focus         Eyes         Face         Near       Action  \\\n",
       "count    9912.000000  9912.000000  9912.000000  9912.000000  9912.000000   \n",
       "mean        0.027643     0.772599     0.903955     0.861582     0.009988   \n",
       "std         0.163957     0.419175     0.294668     0.345356     0.099444   \n",
       "min         0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%         0.000000     1.000000     1.000000     1.000000     0.000000   \n",
       "50%         0.000000     1.000000     1.000000     1.000000     0.000000   \n",
       "75%         0.000000     1.000000     1.000000     1.000000     0.000000   \n",
       "max         1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         Accessory        Group      Collage        Human    Occlusion  \\\n",
       "count  9912.000000  9912.000000  9912.000000  9912.000000  9912.000000   \n",
       "mean      0.067797     0.129338     0.049637     0.166263     0.172014   \n",
       "std       0.251409     0.335591     0.217204     0.372335     0.377411   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              Info         Blur  Pawpularity  \n",
       "count  9912.000000  9912.000000  9912.000000  \n",
       "mean      0.061239     0.070420    38.039044  \n",
       "std       0.239780     0.255866    20.591990  \n",
       "min       0.000000     0.000000     1.000000  \n",
       "25%       0.000000     0.000000    25.000000  \n",
       "50%       0.000000     0.000000    33.000000  \n",
       "75%       0.000000     0.000000    46.000000  \n",
       "max       1.000000     1.000000   100.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale10(n):\n",
    "    val = 0\n",
    "    if n <=10: \n",
    "        val = 1\n",
    "    elif n >10 and n<=20:\n",
    "        val = 2\n",
    "    elif n >20 and n <=30:\n",
    "        val = 3\n",
    "    elif n>30 and n <=40:\n",
    "        val = 4\n",
    "    elif n > 40 and n<=50:\n",
    "        val = 5\n",
    "    elif n>50 and n<=60:\n",
    "        val = 6\n",
    "    elif n>60 and n<=70:\n",
    "        val = 7\n",
    "    elif n>70 and n<=80:\n",
    "        val = 8\n",
    "    elif n>80 and n<=90:\n",
    "        val = 9\n",
    "    else: \n",
    "        val = 10\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale5(n):\n",
    "    val = 0\n",
    "    if n <=20: \n",
    "        val = 1\n",
    "    elif n >20 and n<=40:\n",
    "        val = 2\n",
    "    elif n >40 and n <=60:\n",
    "        val = 3\n",
    "    elif n>60 and n <=80:\n",
    "        val = 4\n",
    "    else: val = 5\n",
    "\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale4(n):\n",
    "    val = 0\n",
    "    if n <=25: \n",
    "        val = 1\n",
    "    elif n >25 and n<=50:\n",
    "        val = 2\n",
    "    elif n >50 and n <=75:\n",
    "        val = 3\n",
    "    else: \n",
    "        val = 4\n",
    "\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale3(n):\n",
    "    val = 0\n",
    "    if n <=34: \n",
    "        val = 1\n",
    "    elif n >34 and n<=68:\n",
    "        val = 2\n",
    "    else:\n",
    "        val = 3\n",
    "\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale2(n):\n",
    "    val = 0\n",
    "    if n <=50: \n",
    "        val = 1\n",
    "    else:\n",
    "        val = 2\n",
    "\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale10\"] = df_data.apply(lambda row: scale10(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale5\"] = df_data.apply(lambda row: scale5(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale4\"] = df_data.apply(lambda row: scale4(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale3\"] = df_data.apply(lambda row: scale3(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale2\"] = df_data.apply(lambda row: scale2(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>Scale10</th>\n",
       "      <th>Scale5</th>\n",
       "      <th>Scale4</th>\n",
       "      <th>Scale3</th>\n",
       "      <th>Scale2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \\\n",
       "0          0      1        0      0          0     0     0           63   \n",
       "1          0      0        0      0          0     0     0           42   \n",
       "2          0      0        0      1          1     0     0           28   \n",
       "3          0      0        0      0          0     0     0           15   \n",
       "4          0      1        0      0          0     0     0           72   \n",
       "\n",
       "   Scale10  Scale5  Scale4  Scale3  Scale2  \n",
       "0        7       4       3       2       2  \n",
       "1        5       3       2       2       1  \n",
       "2        3       2       2       1       1  \n",
       "3        2       1       1       1       1  \n",
       "4        8       4       3       3       2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
       "       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'Pawpularity',\n",
       "       'Scale10', 'Scale5', 'Scale4', 'Scale3', 'Scale2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsL = df_data.columns\n",
    "columnsL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get X and Y data - shuffle data.\n",
    "X_cols = ['Subject Focus','Eyes', 'Face','Near','Action','Accessory','Group','Collage','Human','Occlusion','Info','Blur',]\n",
    "X = np.array(df_data[X_cols])\n",
    "Y = df_data['Pawpularity'].values[:]\n",
    "\n",
    "id_image = df_data['Id'].values[:]\n",
    "\n",
    "Y10 = df_data['Scale10'].values[:]\n",
    "Y5 = df_data['Scale5'].values[:]\n",
    "Y4 = df_data['Scale4'].values[:]\n",
    "Y3 = df_data['Scale3'].values[:]\n",
    "Y2 = df_data['Scale2'].values[:]\n",
    "\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y, id_image = X[shuffle], Y[shuffle], id_image[shuffle]\n",
    "Y10, Y5, Y4, Y3, Y2 = Y10[shuffle], Y5[shuffle], Y4[shuffle], Y3[shuffle], Y2[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sizes for train, development and test data (0.5, 0.2, 0.3)\n",
    "per_train = 0.5\n",
    "per_dev = 0.2\n",
    "\n",
    "num_images = len(Y)\n",
    "train_size = int(round(num_images * per_train,0))\n",
    "dev_size = int(round(num_images * per_dev,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9912\n",
      "(4956, 12) (4956,) (4956,)\n",
      "(1982, 12) (1982,) (1982,)\n",
      "(2974, 12) (2974,) (2974,)\n",
      "(2974,) (1982,) (4956,)\n",
      "(2974,) (1982,) (4956,)\n",
      "(2974,) (1982,) (4956,)\n",
      "(2974,) (1982,) (4956,)\n",
      "(2974,) (1982,) (4956,)\n"
     ]
    }
   ],
   "source": [
    "# Split data based on defined sizes\n",
    "test_data, test_labels, id_test = X[train_size+dev_size:], Y[train_size+dev_size:], id_image[train_size+dev_size:]\n",
    "test_y10 = Y10[train_size+dev_size:]\n",
    "test_y5 = Y5[train_size+dev_size:]\n",
    "test_y4 = Y4[train_size+dev_size:]\n",
    "test_y3 = Y3[train_size+dev_size:]\n",
    "test_y2 = Y2[train_size+dev_size:]\n",
    "\n",
    "dev_data, dev_labels, id_dev = X[train_size:train_size+dev_size], Y[train_size:train_size+dev_size], id_image[train_size:train_size+dev_size]\n",
    "dev_y10 = Y10[train_size:train_size+dev_size]\n",
    "dev_y5 = Y5[train_size:train_size+dev_size]\n",
    "dev_y4 = Y4[train_size:train_size+dev_size]\n",
    "dev_y3 = Y3[train_size:train_size+dev_size]\n",
    "dev_y2 = Y2[train_size:train_size+dev_size]\n",
    "\n",
    "train_data, train_labels, id_train = X[:train_size], Y[:train_size], id_image[:train_size]\n",
    "train_y10 =  Y10[:train_size]\n",
    "train_y5 =  Y5[:train_size]\n",
    "train_y4 =  Y4[:train_size]\n",
    "train_y3 =  Y3[:train_size]\n",
    "train_y2 =  Y2[:train_size]\n",
    "\n",
    "print(num_images)\n",
    "print(train_data.shape, train_labels.shape, id_train.shape)\n",
    "print(dev_data.shape, dev_labels.shape, id_dev.shape)\n",
    "print(test_data.shape, test_labels.shape, id_test.shape)\n",
    "print(test_y10.shape, dev_y10.shape, train_y10.shape)\n",
    "print(test_y5.shape, dev_y5.shape, train_y5.shape)\n",
    "print(test_y4.shape, dev_y4.shape, train_y4.shape)\n",
    "print(test_y3.shape, dev_y3.shape, train_y3.shape)\n",
    "print(test_y2.shape, dev_y2.shape, train_y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrt_excel(file, sheet_name, df):\n",
    "    if os.path.exists(file):\n",
    "        with pd.ExcelWriter(file, engine=\"openpyxl\", mode='a') as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name)\n",
    "    else:\n",
    "        with pd.ExcelWriter(file, engine=\"openpyxl\") as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = []\n",
    "rmse = []\n",
    "acc = []\n",
    "hamm = []\n",
    "\n",
    "knn_mod = KNeighborsClassifier(n_neighbors=2, algorithm=\"auto\", weights=\"uniform\", p=1)\n",
    "knn_mod.fit(train_data, train_labels)\n",
    "acc.append(knn_mod.score(dev_data, dev_labels))\n",
    "f1_score.append(metrics.f1_score(dev_labels, knn_mod.predict(dev_data), average=\"weighted\"))\n",
    "rmse.append(metrics.mean_squared_error(dev_labels, knn_mod.predict(dev_data), squared=False))\n",
    "hamm.append(metrics.hamming_loss(dev_labels, knn_mod.predict(dev_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(train_data, train_labels, dev_data, dev_labels, algorithm, weigth, klist):\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for k in klist:\n",
    "        knn_mod = KNeighborsClassifier(n_neighbors=k, algorithm=algorithm, weights=weigth, p=1)\n",
    "        knn_mod.fit(train_data, train_labels)\n",
    "        acc.append(knn_mod.score(dev_data, dev_labels))\n",
    "        f1_score.append(metrics.f1_score(dev_labels, knn_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, knn_mod.predict(dev_data), squared=False))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, knn_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "    \n",
    "def knn_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_knn = pd.DataFrame()\n",
    "    klist = [1, 2, 3, 4, 5, 6, 7,8,9, 10, 11, 12, 13, 14, 15]\n",
    "    algorithm_list = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "   \n",
    "    weights = [\"uniform\", \"distance\"]\n",
    "    df_knn[\"K\"] = klist\n",
    "\n",
    "    for algorithm in algorithm_list:\n",
    "        df_knn[algorithm+\"_f1\"], df_knn[algorithm+\"_rmse\"], df_knn[algorithm+\"_acc\"], df_knn[algorithm+\"_hamm\"]  = knn_model(train_data, Y_train, dev_data, Y_dev, algorithm, weights[1], klist)\n",
    "        \n",
    "    print(df_knn)\n",
    "    print(\"df_knn\")\n",
    "    return(df_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_model(train_data, train_labels, dev_data, dev_labels, alpha_list):\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for alpha in alpha_list:\n",
    "        NB_mod = BernoulliNB(alpha=alpha)\n",
    "        NB_mod.fit(train_data, train_labels)\n",
    "        acc.append(NB_mod.score(dev_data, dev_labels))\n",
    "        f1_score.append(metrics.f1_score(dev_labels, NB_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, NB_mod.predict(dev_data), squared=False))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, NB_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def NB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    alpha_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "    df_NB = pd.DataFrame()\n",
    "    df_NB[\"Alpha\"] = alpha_list\n",
    "    df_NB[\"F1_score\"], df_NB[\"RMSE\"], df_NB[\"ACC\"], df_NB[\"HAMM\"] = NB_model(train_data, Y_train, dev_data, Y_dev, alpha_list)\n",
    "\n",
    "    print(df_NB)\n",
    "    print(\"df_NB\")\n",
    "    return(df_NB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNB_model(train_data, train_labels, dev_data, dev_labels, alpha_list):\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for alpha in alpha_list:\n",
    "        MNB_mod = MultinomialNB(alpha=alpha)\n",
    "        MNB_mod.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, MNB_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, MNB_mod.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, MNB_mod.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, MNB_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def MNB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    alpha_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "    df_MNB = pd.DataFrame()\n",
    "    df_MNB[\"Alpha\"] = alpha_list\n",
    "    df_MNB[\"F1_score\"], df_MNB[\"RMSE\"], df_MNB[\"ACC\"], df_MNB[\"HAMM\"] = MNB_model(train_data, Y_train, \n",
    "                                                                                  dev_data, Y_dev, alpha_list)\n",
    "\n",
    "    print(df_MNB)\n",
    "    print(\"df_MNB\")\n",
    "    return(df_MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB (only classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNB_model(train_data, train_labels, dev_data, dev_labels, smoothing_list):\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for var_smoothing in smoothing_list:\n",
    "        GNB_mod = GaussianNB(var_smoothing=var_smoothing)\n",
    "        GNB_mod.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, GNB_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, GNB_mod.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, GNB_mod.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, GNB_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def GNB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    smoothing_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "    df_GNB = pd.DataFrame()\n",
    "    df_GNB[\"Var Smooth\"] = smoothing_list\n",
    "    df_GNB[\"F1_score\"], df_GNB[\"RMSE\"], df_GNB[\"ACC\"], df_GNB[\"HAMM\"] = GNB_model(train_data, Y_train, dev_data, Y_dev, smoothing_list)\n",
    "\n",
    "    print(df_GNB)\n",
    "    print(\"df_GNB\")\n",
    "    return(df_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression\n",
    "Warning The choice of the algorithm depends on the penalty chosen: Supported penalties by solver:  \n",
    "- ‘newton-cg’ - [‘l2’, ‘none’]  \n",
    "- ‘lbfgs’ - [‘l2’, ‘none’]  \n",
    "- ‘liblinear’ - [‘l1’, ‘l2’]  \n",
    "- ‘sag’ - [‘l2’, ‘none’]  \n",
    "- ‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, ‘none’]\n",
    "\n",
    "**max_iter was increased to 200, so it would converge**\n",
    "- max_iter int, default=100\n",
    "- Maximum number of iterations taken for the solvers to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogR_model(train_data, train_labels, dev_data, dev_labels, penalty, solver, c_list):\n",
    "    \n",
    "    \n",
    "    #c_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for c in c_list:\n",
    "        logR_mod = LogisticRegression(C=c, solver=solver, multi_class=\"auto\", penalty=penalty, max_iter=200)\n",
    "        logR_mod.fit(train_data, train_labels)\n",
    "        acc.append(logR_mod.score(dev_data, dev_labels))\n",
    "        f1_score.append(metrics.f1_score(dev_labels, logR_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, logR_mod.predict(dev_data), squared=False))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, logR_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def LogR_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_logR =pd.DataFrame()\n",
    "    solver_list = [\"liblinear\", \"newton-cg\", \"sag\", \"lbfgs\"]\n",
    "    c_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "    df_logR[\"C\"] = c_list\n",
    "    for solver in solver_list:\n",
    "#         df_logR[solver] = LogR_model(train_data, Y_train, dev_data, Y_dev, \"l2\", solver, c_list)\n",
    "        df_logR[solver+\"_f1\"], df_logR[solver+\"_rmse\"], df_logR[solver+\"_acc\"], df_logR[solver+\"_hamm\"]= LogR_model(train_data, Y_train, dev_data, Y_dev, \"l2\", solver, c_list)\n",
    "\n",
    "    print(df_logR)\n",
    "    print(\"df_LogR\")\n",
    "    return(df_logR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree (Regression) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_model(train_data, train_labels, dev_data, dev_labels, criterion, max_depth_list):\n",
    "    \n",
    "    \n",
    "    #c_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse=[]\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for max_depth in max_depth_list:\n",
    "        dt_model = DecisionTreeClassifier(criterion=criterion, min_samples_split=10, max_depth=max_depth)\n",
    "#         dt_model = DecisionTreeRegressor(criterion=criterion, min_samples_split=10, max_depth=max_depth)\n",
    "        dt_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, dt_model.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, dt_model.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, dt_model.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, dt_model.predict(dev_data)))       \n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def DT_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_DT =pd.DataFrame()\n",
    "    criterion_list = [\"entropy\", \"gini\"]\n",
    "    max_depth_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    df_DT[\"max_depth\"] = max_depth_list\n",
    "\n",
    "    for criterion in criterion_list:\n",
    "#         df_DT[criterion] = DT_model(train_data, Y_train, dev_data, Y_dev, criterion, max_depth_list)\n",
    "        df_DT[criterion+\"_f1\"], df_DT[criterion+\"_rmse\"], df_DT[criterion+\"_acc\"], df_DT[criterion+\"_hamm\"]= DT_model(train_data, \n",
    "                                                                                                                      Y_train, dev_data, \n",
    "                                                                                                                      Y_dev, criterion, max_depth_list)\n",
    "\n",
    "    print(df_DT)\n",
    "    print(\"df_DT\")\n",
    "    return(df_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(train_data, train_labels, dev_data, dev_labels, criterion, n_estimators_list):\n",
    "        \n",
    "    f1_score = []\n",
    "    rmse=[]\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for n_estimators in n_estimators_list:\n",
    "        RF_model = RandomForestClassifier(n_estimators=n_estimators,criterion=criterion, min_samples_split=10)\n",
    "        RF_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, RF_model.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, RF_model.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, RF_model.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, RF_model.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def RF_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_RF =pd.DataFrame()\n",
    "    criterion_list = [\"entropy\", \"gini\"]\n",
    "    n_estimators_list = [5, 10, 15, 20, 25, 30]\n",
    "    df_RF[\"n_estimators\"] = n_estimators_list\n",
    "\n",
    "    for criterion in criterion_list:\n",
    "#         df_RF[criterion] = RF_model(train_data, Y_train, dev_data, Y_dev, criterion, n_estimators_list)\n",
    "        df_RF[criterion+\"_f1\"], df_RF[criterion+\"_rmse\"], df_RF[criterion+\"_acc\"], df_RF[criterion+\"_hamm\"]= RF_model(train_data, Y_train, dev_data, Y_dev, \n",
    "                                                                   criterion, n_estimators_list)\n",
    "\n",
    "    print(df_RF)\n",
    "    print(\"df_RF\")\n",
    "    return(df_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaB_model(train_data, train_labels, dev_data, dev_labels, algorithm, n_estimators_list):\n",
    "        \n",
    "    f1_score = []\n",
    "    rmse=[]\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for n_estimators in n_estimators_list:\n",
    "        AdaB_model = AdaBoostClassifier(n_estimators=n_estimators,algorithm=algorithm, learning_rate=1.2)\n",
    "        AdaB_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, AdaB_model.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, AdaB_model.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, AdaB_model.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, AdaB_model.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def AdaB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_AdaB =pd.DataFrame()\n",
    "    algorithm_list = [\"SAMME\", \"SAMME.R\"]\n",
    "    n_estimators_list = [5, 10, 15, 20, 25, 30]\n",
    "    df_AdaB[\"n_estimators\"] = n_estimators_list\n",
    "\n",
    "    for algorithm in algorithm_list:\n",
    "        df_AdaB[algorithm+\"_f1\"], df_AdaB[algorithm+\"_rmse\"], df_AdaB[algorithm+\"_acc\"], df_AdaB[algorithm+\"_hamm\"]= AdaB_model(train_data, Y_train, \n",
    "                                                                         dev_data, Y_dev, algorithm, n_estimators_list)\n",
    "\n",
    "    print(df_AdaB)\n",
    "    print(\"df_AdaB\")\n",
    "    return(df_AdaB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(train_data, train_labels, dev_data, dev_labels, kernel, c_list):\n",
    "        \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for c in c_list:\n",
    "        if kernel == \"LinearSVC\":\n",
    "            svm_model = svm.LinearSVC(C=c, max_iter=10000)\n",
    "        elif kernel == \"poly\":\n",
    "            svm_model = svm.SVC(kernel=kernel, C=c, degree=2, gamma=1)\n",
    "        elif kernel == \"rbf\":\n",
    "            svm_model = svm.SVC(kernel=kernel, C=c, gamma=0.7)\n",
    "        else:\n",
    "            svm_model = svm.SVC(kernel=kernel, C=c,)\n",
    "        \n",
    "        svm_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, svm_model.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, svm_model.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, svm_model.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, svm_model.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def SVM_models(train_data, Y_train, dev_data):\n",
    "    df_SVM =pd.DataFrame()\n",
    "    kernel_list = [\"linear\", \"rbf\", \"poly\", \"LinearSVC\"]\n",
    "    c_list = [0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 10, 20]\n",
    "    df_SVM[\"C\"] = c_list\n",
    "\n",
    "    for kernel in kernel_list:\n",
    "        df_SVM[kernel+\"_f1\"], df_SVM[kernel+\"_rmse\"], df_SVM[kernel+\"_acc\"], df_SVM[kernel+\"_hamm\"] = SVM_model(train_data, Y_train, dev_data, Y_dev, kernel, c_list)\n",
    "    print(df_SVM)\n",
    "    print(\"df_SVM\")\n",
    "\n",
    "    return(df_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "**hidden_layer_sizestuple, length = n_layers - 2, default=(100,)**  \n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "**activation{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’**  \n",
    "Activation function for the hidden layer.  \n",
    "\n",
    "- ‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x  \n",
    "- ‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).  \n",
    "- ‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).   \n",
    "- ‘relu’, the rectified linear unit function, returns f(x) = max(0, x)  \n",
    "\n",
    "**solver{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’**  \n",
    "The solver for weight optimization.  \n",
    "\n",
    "- ‘lbfgs’ is an optimizer in the family of quasi-Newton methods.\n",
    "- ‘sgd’ refers to stochastic gradient descent.\n",
    "- ‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "\n",
    "Note: The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.\n",
    "\n",
    "**alphafloat, default=0.0001**\n",
    "L2 penalty (regularization term) parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(train_data, train_labels, dev_data, dev_labels, activation, solver_list, alpha_list, layer_list, choice):\n",
    "        \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    if choice == \"A\":\n",
    "        for alpha in alpha_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000, activation=activation, alpha=alpha)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "            rmse.append(metrics.mean_squared_error(dev_labels, NN_model.predict(dev_data), squared=False))\n",
    "            acc.append(metrics.accuracy_score(dev_labels, NN_model.predict(dev_data)))\n",
    "            hamm.append(metrics.hamming_loss(dev_labels, NN_model.predict(dev_data)))\n",
    "    elif choice == \"L\":\n",
    "        for layer in layer_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=layer, max_iter=1000, activation=activation)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "            rmse.append(metrics.mean_squared_error(dev_labels, NN_model.predict(dev_data), squared=False))\n",
    "            acc.append(metrics.accuracy_score(dev_labels, NN_model.predict(dev_data)))\n",
    "            hamm.append(metrics.hamming_loss(dev_labels, NN_model.predict(dev_data)))\n",
    "    else:\n",
    "        for solver in solver_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=8000, activation=activation, solver=solver)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "            rmse.append(metrics.mean_squared_error(dev_labels, NN_model.predict(dev_data), squared=False))\n",
    "            acc.append(metrics.accuracy_score(dev_labels, NN_model.predict(dev_data)))\n",
    "            hamm.append(metrics.hamming_loss(dev_labels, NN_model.predict(dev_data)))\n",
    "    \n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "#Note: Changing Alpha is not creating any variation in the f1_score.  Try first with L and then with S\n",
    "def NN_models(train_data, Y_train, dev_data, Y_dev, choice):\n",
    "    \n",
    "    df_NN =pd.DataFrame()\n",
    "    activation_list = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "    layer_list = [(10,10,10), (5,5,5), (3,3,3), (20, 20, 20)]\n",
    "    solver_list = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "    alpha_list = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.5]\n",
    "\n",
    "    for activation in activation_list:\n",
    "        df_NN[activation+'_f1'], df_NN[activation+'_rmse'], df_NN[activation+'_acc'], df_NN[activation+'_hamm'] = NN_model(train_data, Y_train, dev_data, Y_dev, activation, solver_list, alpha_list, layer_list, choice)\n",
    "\n",
    "    if choice == \"A\":\n",
    "        df_NN[\"Alpha\"] = alpha_list\n",
    "    elif choice == \"L\":\n",
    "        df_NN[\"Layers\"] = layer_list\n",
    "    else:\n",
    "        df_NN[\"Solver\"] = solver_list\n",
    "    \n",
    "    print(df_NN)\n",
    "    print(\"df_NN\")\n",
    "    return(df_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_y(scale):\n",
    "    if scale == 2:\n",
    "        Y_train = train_y2\n",
    "        Y_dev = dev_y2\n",
    "    elif scale == 3:\n",
    "        Y_train = train_y3\n",
    "        Y_dev = dev_y3\n",
    "    elif scale == 4:\n",
    "        Y_train = train_y4\n",
    "        Y_dev = dev_y4\n",
    "    elif scale == 5:\n",
    "        Y_train = train_y5\n",
    "        Y_dev = dev_y5\n",
    "    elif scale == 10:\n",
    "        Y_train = train_y10\n",
    "        Y_dev = dev_y10\n",
    "    elif scale == 100:\n",
    "        Y_train = train_labels\n",
    "        Y_dev = dev_labels\n",
    "    else:\n",
    "        Y_train = train_labels\n",
    "        Y_dev = dev_labels\n",
    "    return(Y_train, Y_dev)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(Y_dev, Prediction, title):\n",
    "    cfm = confusion_matrix(Y_dev,Prediction)\n",
    "    if np.unique(Y_dev).max() > 5:\n",
    "        size = 6\n",
    "    else: \n",
    "        size = np.unique(Y_dev).max()\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(cfm, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(cfm.shape[0]):\n",
    "        for j in range(cfm.shape[1]):\n",
    "            ax.text(x=j, y=i,s=cfm[i, j], va='center', ha='center', size='xx-large')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.577796   0.680194  0.537336   0.462664      0.579138   \n",
      "1    2  0.694264   0.470095  0.779011   0.220989      0.694534   \n",
      "2    3  0.702511   0.478076  0.771443   0.228557      0.702511   \n",
      "3    4  0.688322   0.469558  0.779516   0.220484      0.688322   \n",
      "4    5  0.693183   0.472236  0.776993   0.223007      0.693183   \n",
      "5    6  0.686968   0.468482  0.780525   0.219475      0.686968   \n",
      "6    7  0.692004   0.471167  0.778002   0.221998      0.692004   \n",
      "7    8  0.687217   0.467943  0.781029   0.218971      0.687217   \n",
      "8    9  0.687217   0.467943  0.781029   0.218971      0.687217   \n",
      "9   10  0.687217   0.467943  0.781029   0.218971      0.687217   \n",
      "10  11  0.687217   0.467943  0.781029   0.218971      0.687217   \n",
      "11  12  0.687217   0.467943  0.781029   0.218971      0.687217   \n",
      "12  13  0.687217   0.467943  0.781029   0.218971      0.687217   \n",
      "13  14  0.686968   0.468482  0.780525   0.219475      0.687217   \n",
      "14  15  0.687217   0.467943  0.781029   0.218971      0.687217   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0         0.679081       0.538850        0.461150    0.577796      0.680194   \n",
      "1         0.469558       0.779516        0.220484    0.694264      0.470095   \n",
      "2         0.478076       0.771443        0.228557    0.702511      0.478076   \n",
      "3         0.469558       0.779516        0.220484    0.688322      0.469558   \n",
      "4         0.472236       0.776993        0.223007    0.693183      0.472236   \n",
      "5         0.468482       0.780525        0.219475    0.686968      0.468482   \n",
      "6         0.471167       0.778002        0.221998    0.692004      0.471167   \n",
      "7         0.467943       0.781029        0.218971    0.687217      0.467943   \n",
      "8         0.467943       0.781029        0.218971    0.687217      0.467943   \n",
      "9         0.467943       0.781029        0.218971    0.687217      0.467943   \n",
      "10        0.467943       0.781029        0.218971    0.687217      0.467943   \n",
      "11        0.467943       0.781029        0.218971    0.687217      0.467943   \n",
      "12        0.467943       0.781029        0.218971    0.687217      0.467943   \n",
      "13        0.467943       0.781029        0.218971    0.686968      0.468482   \n",
      "14        0.467943       0.781029        0.218971    0.687217      0.467943   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.537336      0.462664  0.693423    0.497217   0.752775    0.247225  \n",
      "1      0.779011      0.220989  0.691543    0.480182   0.769425    0.230575  \n",
      "2      0.771443      0.228557  0.691828    0.485408   0.764379    0.235621  \n",
      "3      0.779516      0.220484  0.585520    0.673110   0.546922    0.453078  \n",
      "4      0.776993      0.223007  0.581641    0.676475   0.542381    0.457619  \n",
      "5      0.780525      0.219475  0.693121    0.480182   0.769425    0.230575  \n",
      "6      0.778002      0.221998  0.695944    0.483324   0.766398    0.233602  \n",
      "7      0.781029      0.218971  0.691290    0.475961   0.773461    0.226539  \n",
      "8      0.781029      0.218971  0.694746    0.478604   0.770938    0.229062  \n",
      "9      0.781029      0.218971  0.691395    0.470631   0.778507    0.221493  \n",
      "10     0.781029      0.218971  0.691395    0.470631   0.778507    0.221493  \n",
      "11     0.781029      0.218971  0.687217    0.467943   0.781029    0.218971  \n",
      "12     0.781029      0.218971  0.691395    0.470631   0.778507    0.221493  \n",
      "13     0.780525      0.219475  0.687217    0.467943   0.781029    0.218971  \n",
      "14     0.781029      0.218971  0.687217    0.467943   0.781029    0.218971  \n",
      "df_knn\n",
      "          Alpha  F1_score     RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.688462  0.46524  0.783552  0.216448\n",
      "1  1.000000e-04  0.688462  0.46524  0.783552  0.216448\n",
      "2  1.000000e-03  0.688462  0.46524  0.783552  0.216448\n",
      "3  1.000000e-02  0.688462  0.46524  0.783552  0.216448\n",
      "4  1.000000e-01  0.688462  0.46524  0.783552  0.216448\n",
      "5  5.000000e-01  0.688462  0.46524  0.783552  0.216448\n",
      "6  1.000000e+00  0.688462  0.46524  0.783552  0.216448\n",
      "7  2.000000e+00  0.688462  0.46524  0.783552  0.216448\n",
      "8  1.000000e+01  0.688462  0.46524  0.783552  0.216448\n",
      "df_NB\n",
      "          Alpha  F1_score     RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.688462  0.46524  0.783552  0.216448\n",
      "1  1.000000e-04  0.688462  0.46524  0.783552  0.216448\n",
      "2  1.000000e-03  0.688462  0.46524  0.783552  0.216448\n",
      "3  1.000000e-02  0.688462  0.46524  0.783552  0.216448\n",
      "4  1.000000e-01  0.688462  0.46524  0.783552  0.216448\n",
      "5  5.000000e-01  0.688462  0.46524  0.783552  0.216448\n",
      "6  1.000000e+00  0.688462  0.46524  0.783552  0.216448\n",
      "7  2.000000e+00  0.688462  0.46524  0.783552  0.216448\n",
      "8  1.000000e+01  0.688462  0.46524  0.783552  0.216448\n",
      "df_MNB\n",
      "     Var Smooth  F1_score      RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.684999  0.481756  0.767911  0.232089\n",
      "1  1.000000e-04  0.684999  0.481756  0.767911  0.232089\n",
      "2  1.000000e-03  0.684999  0.481756  0.767911  0.232089\n",
      "3  1.000000e-02  0.685263  0.481232  0.768416  0.231584\n",
      "4  1.000000e-01  0.688213  0.465782  0.783047  0.216953\n",
      "5  5.000000e-01  0.688462  0.465240  0.783552  0.216448\n",
      "6  1.000000e+00  0.688462  0.465240  0.783552  0.216448\n",
      "7  2.000000e+00  0.688462  0.465240  0.783552  0.216448\n",
      "8  1.000000e+01  0.688462  0.465240  0.783552  0.216448\n",
      "df_GNB\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1      0.688462         0.46524       0.783552        0.216448   \n",
      "1    2      0.688462         0.46524       0.783552        0.216448   \n",
      "2    3      0.688462         0.46524       0.783552        0.216448   \n",
      "3    4      0.688462         0.46524       0.783552        0.216448   \n",
      "4    5      0.688462         0.46524       0.783552        0.216448   \n",
      "5    6      0.688462         0.46524       0.783552        0.216448   \n",
      "6    7      0.688462         0.46524       0.783552        0.216448   \n",
      "7    8      0.688462         0.46524       0.783552        0.216448   \n",
      "8    9      0.688462         0.46524       0.783552        0.216448   \n",
      "9   10      0.688462         0.46524       0.783552        0.216448   \n",
      "10  11      0.688462         0.46524       0.783552        0.216448   \n",
      "11  12      0.688462         0.46524       0.783552        0.216448   \n",
      "12  13      0.688462         0.46524       0.783552        0.216448   \n",
      "13  14      0.688462         0.46524       0.783552        0.216448   \n",
      "14  15      0.688462         0.46524       0.783552        0.216448   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "1       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "2       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "3       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "4       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "5       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "6       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "7       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "8       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "9       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "10      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "11      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "12      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "13      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "14      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "\n",
      "    sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "1    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "2    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "3    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "4    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "5    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "6    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "7    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "8    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "9    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "10   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "11   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "12   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "13   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "14   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.688462      0.465240     0.783552      0.216448  0.688462   \n",
      "1           2    0.688462      0.465240     0.783552      0.216448  0.688462   \n",
      "2           3    0.687964      0.466323     0.782543      0.217457  0.687964   \n",
      "3           4    0.689161      0.465782     0.783047      0.216953  0.689161   \n",
      "4           5    0.688910      0.466323     0.782543      0.217457  0.688659   \n",
      "5           6    0.688659      0.466864     0.782038      0.217962  0.688659   \n",
      "6           7    0.687652      0.469020     0.780020      0.219980  0.688831   \n",
      "7           8    0.688067      0.470095     0.779011      0.220989  0.689235   \n",
      "8           9    0.688978      0.470095     0.779011      0.220989  0.687813   \n",
      "9          10    0.687813      0.470631     0.778507      0.221493  0.687813   \n",
      "10         11    0.688978      0.470095     0.779011      0.220989  0.688978   \n",
      "11         12    0.688978      0.470095     0.779011      0.220989  0.688978   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0    0.465240  0.783552   0.216448  \n",
      "1    0.465240  0.783552   0.216448  \n",
      "2    0.466323  0.782543   0.217457  \n",
      "3    0.465782  0.783047   0.216953  \n",
      "4    0.466864  0.782038   0.217962  \n",
      "5    0.466864  0.782038   0.217962  \n",
      "6    0.468482  0.780525   0.219475  \n",
      "7    0.469558  0.779516   0.220484  \n",
      "8    0.470631  0.778507   0.221493  \n",
      "9    0.470631  0.778507   0.221493  \n",
      "10   0.470095  0.779011   0.220989  \n",
      "11   0.470095  0.779011   0.220989  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.687964      0.466323     0.782543      0.217457   \n",
      "1            10    0.689161      0.465782     0.783047      0.216953   \n",
      "2            15    0.687715      0.466864     0.782038      0.217962   \n",
      "3            20    0.687148      0.470095     0.779011      0.220989   \n",
      "4            25    0.687964      0.466323     0.782543      0.217457   \n",
      "5            30    0.687964      0.466323     0.782543      0.217457   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.689593   0.466864  0.782038   0.217962  \n",
      "1  0.689748   0.468482  0.780525   0.219475  \n",
      "2  0.688156   0.467943  0.781029   0.218971  \n",
      "3  0.688659   0.466864  0.782038   0.217962  \n",
      "4  0.687715   0.466864  0.782038   0.217962  \n",
      "5  0.687964   0.466323  0.782543   0.217457  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "1            10  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "2            15  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "3            20  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "4            25  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "5            30  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0       0.46524     0.783552      0.216448  \n",
      "1       0.46524     0.783552      0.216448  \n",
      "2       0.46524     0.783552      0.216448  \n",
      "3       0.46524     0.783552      0.216448  \n",
      "4       0.46524     0.783552      0.216448  \n",
      "5       0.46524     0.783552      0.216448  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1  rbf_rmse  \\\n",
      "0   0.5   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "1   1.0   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "2   1.5   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "3   2.0   0.688462      0.46524    0.783552     0.216448  0.688213  0.465782   \n",
      "4   2.5   0.688462      0.46524    0.783552     0.216448  0.687715  0.466864   \n",
      "5   3.0   0.688462      0.46524    0.783552     0.216448  0.686469  0.469558   \n",
      "6   4.0   0.688462      0.46524    0.783552     0.216448  0.687813  0.470631   \n",
      "7   5.0   0.688462      0.46524    0.783552     0.216448  0.687558  0.471167   \n",
      "8  10.0   0.688462      0.46524    0.783552     0.216448  0.687303  0.471702   \n",
      "9  20.0   0.688462      0.46524    0.783552     0.216448  0.687303  0.471702   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.783552  0.216448  0.687715   0.466864  0.782038   0.217962      0.688462   \n",
      "1  0.783552  0.216448  0.687466   0.467404  0.781534   0.218466      0.688462   \n",
      "2  0.783552  0.216448  0.687466   0.467404  0.781534   0.218466      0.688462   \n",
      "3  0.783047  0.216953  0.687466   0.467404  0.781534   0.218466      0.688462   \n",
      "4  0.782038  0.217962  0.687466   0.467404  0.781534   0.218466      0.688462   \n",
      "5  0.779516  0.220484  0.687466   0.467404  0.781534   0.218466      0.688462   \n",
      "6  0.778507  0.221493  0.687466   0.467404  0.781534   0.218466      0.688462   \n",
      "7  0.778002  0.221998  0.687466   0.467404  0.781534   0.218466      0.688462   \n",
      "8  0.777497  0.222503  0.687466   0.467404  0.781534   0.218466      0.688462   \n",
      "9  0.777497  0.222503  0.687466   0.467404  0.781534   0.218466      0.688462   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0         0.46524       0.783552        0.216448  \n",
      "1         0.46524       0.783552        0.216448  \n",
      "2         0.46524       0.783552        0.216448  \n",
      "3         0.46524       0.783552        0.216448  \n",
      "4         0.46524       0.783552        0.216448  \n",
      "5         0.46524       0.783552        0.216448  \n",
      "6         0.46524       0.783552        0.216448  \n",
      "7         0.46524       0.783552        0.216448  \n",
      "8         0.46524       0.783552        0.216448  \n",
      "9         0.46524       0.783552        0.216448  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "1     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "2     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "3     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "1        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "2        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "3        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.216448  0.688462    0.46524  0.783552   0.216448  (10, 10, 10)  \n",
      "1   0.216448  0.688462    0.46524  0.783552   0.216448     (5, 5, 5)  \n",
      "2   0.216448  0.688462    0.46524  0.783552   0.216448     (3, 3, 3)  \n",
      "3   0.216448  0.689412    0.46524  0.783552   0.216448  (20, 20, 20)  \n",
      "df_NN\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "1     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "2     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        0.46524      0.783552       0.216448  0.686404   0.475431  0.773966   \n",
      "1        0.46524      0.783552       0.216448  0.688462   0.465240  0.783552   \n",
      "2        0.46524      0.783552       0.216448  0.688462   0.465240  0.783552   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.226034  0.688155   0.475431  0.773966   0.226034  lbfgs  \n",
      "1   0.216448  0.688462   0.465240  0.783552   0.216448    sgd  \n",
      "2   0.216448  0.688659   0.466864  0.782038   0.217962   adam  \n",
      "df_NN\n",
      "5\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.278688   2.015830  0.259334   0.740666      0.277788   \n",
      "1    2  0.365195   1.217307  0.457114   0.542886      0.365571   \n",
      "2    3  0.276719   1.485891  0.280020   0.719980      0.276521   \n",
      "3    4  0.290909   1.472931  0.298184   0.701816      0.291150   \n",
      "4    5  0.373064   1.198932  0.457114   0.542886      0.372674   \n",
      "5    6  0.317379   1.415462  0.327447   0.672553      0.316244   \n",
      "6    7  0.305124   1.428236  0.319879   0.680121      0.303853   \n",
      "7    8  0.368226   1.150615  0.464178   0.535822      0.368226   \n",
      "8    9  0.365732   1.150177  0.461655   0.538345      0.366113   \n",
      "9   10  0.366470   1.148421  0.464682   0.535318      0.367247   \n",
      "10  11  0.370576   1.126688  0.480323   0.519677      0.370781   \n",
      "11  12  0.367208   1.128701  0.478305   0.521695      0.367721   \n",
      "12  13  0.370590   1.123773  0.491927   0.508073      0.371327   \n",
      "13  14  0.371138   1.127359  0.494955   0.505045      0.371904   \n",
      "14  15  0.365936   1.131826  0.482846   0.517154      0.366766   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0         2.016331       0.258829        0.741171    0.278688      2.015830   \n",
      "1         1.217721       0.457619        0.542381    0.365195      1.217307   \n",
      "2         1.484532       0.280020        0.719980    0.276719      1.485891   \n",
      "3         1.472417       0.298184        0.701816    0.290909      1.472931   \n",
      "4         1.198511       0.456609        0.543391    0.373064      1.198932   \n",
      "5         1.415818       0.326438        0.673562    0.317379      1.415462   \n",
      "6         1.428589       0.318870        0.681130    0.305124      1.428236   \n",
      "7         1.150615       0.464178        0.535822    0.368226      1.150615   \n",
      "8         1.150615       0.462159        0.537841    0.365732      1.150177   \n",
      "9         1.148201       0.465187        0.534813    0.366470      1.148421   \n",
      "10        1.126911       0.479818        0.520182    0.370576      1.126688   \n",
      "11        1.128701       0.478305        0.521695    0.367208      1.128701   \n",
      "12        1.123549       0.492432        0.507568    0.370590      1.123773   \n",
      "13        1.127135       0.495459        0.504541    0.371138      1.127359   \n",
      "14        1.131603       0.483350        0.516650    0.365936      1.131826   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.259334      0.740666  0.367906    1.310133   0.421292    0.578708  \n",
      "1      0.457114      0.542886  0.351192    1.306855   0.410192    0.589808  \n",
      "2      0.280020      0.719980  0.371993    1.233775   0.427851    0.572149  \n",
      "3      0.298184      0.701816  0.326794    1.192391   0.345106    0.654894  \n",
      "4      0.457114      0.542886  0.380992    1.167807   0.467709    0.532291  \n",
      "5      0.327447      0.672553  0.315542    1.183259   0.336024    0.663976  \n",
      "6      0.319879      0.680121  0.382633    1.156083   0.482846    0.517154  \n",
      "7      0.464178      0.535822  0.374497    1.164129   0.489909    0.510091  \n",
      "8      0.461655      0.538345  0.381512    1.172550   0.481332    0.518668  \n",
      "9      0.464682      0.535318  0.375721    1.141149   0.497477    0.502523  \n",
      "10     0.480323      0.519677  0.370356    1.163696   0.490414    0.509586  \n",
      "11     0.478305      0.521695  0.366237    1.131826   0.502523    0.497477  \n",
      "12     0.491927      0.508073  0.370038    1.162611   0.487891    0.512109  \n",
      "13     0.494955      0.505045  0.371647    1.130711   0.498991    0.501009  \n",
      "14     0.482846      0.517154  0.368227    1.135164   0.500505    0.499495  \n",
      "df_knn\n",
      "          Alpha  F1_score      RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.348010  1.109768  0.513118  0.486882\n",
      "1  1.000000e-04  0.348010  1.109768  0.513118  0.486882\n",
      "2  1.000000e-03  0.348010  1.109768  0.513118  0.486882\n",
      "3  1.000000e-02  0.348010  1.109768  0.513118  0.486882\n",
      "4  1.000000e-01  0.348010  1.109768  0.513118  0.486882\n",
      "5  5.000000e-01  0.348010  1.109768  0.513118  0.486882\n",
      "6  1.000000e+00  0.348010  1.109768  0.513118  0.486882\n",
      "7  2.000000e+00  0.348010  1.109768  0.513118  0.486882\n",
      "8  1.000000e+01  0.347679  1.111812  0.511604  0.488396\n",
      "df_NB\n",
      "          Alpha  F1_score      RMSE       ACC      HAMM\n",
      "0  1.000000e-10   0.34801  1.109768  0.513118  0.486882\n",
      "1  1.000000e-04   0.34801  1.109768  0.513118  0.486882\n",
      "2  1.000000e-03   0.34801  1.109768  0.513118  0.486882\n",
      "3  1.000000e-02   0.34801  1.109768  0.513118  0.486882\n",
      "4  1.000000e-01   0.34801  1.109768  0.513118  0.486882\n",
      "5  5.000000e-01   0.34801  1.109768  0.513118  0.486882\n",
      "6  1.000000e+00   0.34801  1.109768  0.513118  0.486882\n",
      "7  2.000000e+00   0.34801  1.109768  0.513118  0.486882\n",
      "8  1.000000e+01   0.34801  1.109768  0.513118  0.486882\n",
      "df_MNB\n",
      "     Var Smooth  F1_score      RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.367072  1.249420  0.426337  0.573663\n",
      "1  1.000000e-04  0.367072  1.249420  0.426337  0.573663\n",
      "2  1.000000e-03  0.367072  1.249420  0.426337  0.573663\n",
      "3  1.000000e-02  0.366249  1.249622  0.425832  0.574168\n",
      "4  1.000000e-01  0.367091  1.232547  0.437941  0.562059\n",
      "5  5.000000e-01  0.352432  1.111358  0.514632  0.485368\n",
      "6  1.000000e+00  0.348010  1.109768  0.513118  0.486882\n",
      "7  2.000000e+00  0.348010  1.109768  0.513118  0.486882\n",
      "8  1.000000e+01  0.348010  1.109768  0.513118  0.486882\n",
      "df_GNB\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1      0.349133         1.10954       0.513623        0.486377   \n",
      "1    2      0.349133         1.10954       0.513623        0.486377   \n",
      "2    3      0.349133         1.10954       0.513623        0.486377   \n",
      "3    4      0.349133         1.10954       0.513623        0.486377   \n",
      "4    5      0.349133         1.10954       0.513623        0.486377   \n",
      "5    6      0.349133         1.10954       0.513623        0.486377   \n",
      "6    7      0.349133         1.10954       0.513623        0.486377   \n",
      "7    8      0.349133         1.10954       0.513623        0.486377   \n",
      "8    9      0.349133         1.10954       0.513623        0.486377   \n",
      "9   10      0.349133         1.10954       0.513623        0.486377   \n",
      "10  11      0.349133         1.10954       0.513623        0.486377   \n",
      "11  12      0.349133         1.10954       0.513623        0.486377   \n",
      "12  13      0.349133         1.10954       0.513623        0.486377   \n",
      "13  14      0.349133         1.10954       0.513623        0.486377   \n",
      "14  15      0.349133         1.10954       0.513623        0.486377   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "1       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "2       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "3       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "4       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "5       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "6       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "7       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "8       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "9       0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "10      0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "11      0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "12      0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "13      0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "14      0.349133         1.10954       0.513623        0.486377  0.349133   \n",
      "\n",
      "    sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "1    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "2    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "3    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "4    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "5    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "6    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "7    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "8    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "9    1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "10   1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "11   1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "12   1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "13   1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "14   1.10954  0.513623  0.486377  0.349133     1.10954   0.513623    0.486377  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.348010      1.109768     0.513118      0.486882  0.348010   \n",
      "1           2    0.348010      1.109768     0.513118      0.486882  0.348010   \n",
      "2           3    0.353716      1.119274     0.511100      0.488900  0.349557   \n",
      "3           4    0.350979      1.111358     0.506054      0.493946  0.348562   \n",
      "4           5    0.358718      1.119725     0.503027      0.496973  0.356476   \n",
      "5           6    0.357401      1.125343     0.503532      0.496468  0.360364   \n",
      "6           7    0.362615      1.132494     0.498991      0.501009  0.362054   \n",
      "7           8    0.368122      1.136053     0.500000      0.500000  0.364003   \n",
      "8           9    0.364875      1.134942     0.501009      0.498991  0.363061   \n",
      "9          10    0.364875      1.134942     0.501009      0.498991  0.363121   \n",
      "10         11    0.364496      1.136053     0.500000      0.500000  0.362835   \n",
      "11         12    0.364496      1.136053     0.500000      0.500000  0.362932   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0    1.109768  0.513118   0.486882  \n",
      "1    1.109768  0.513118   0.486882  \n",
      "2    1.109995  0.512614   0.487386  \n",
      "3    1.110904  0.512109   0.487891  \n",
      "4    1.114531  0.508577   0.491423  \n",
      "5    1.114757  0.506559   0.493441  \n",
      "6    1.128254  0.504541   0.495459  \n",
      "7    1.132717  0.504036   0.495964  \n",
      "8    1.138936  0.502018   0.497982  \n",
      "9    1.140485  0.500000   0.500000  \n",
      "10   1.142474  0.499495   0.500505  \n",
      "11   1.141370  0.499495   0.500505  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.364324      1.137828     0.498486      0.501514   \n",
      "1            10    0.361619      1.118147     0.504541      0.495459   \n",
      "2            15    0.366634      1.130041     0.500000      0.500000   \n",
      "3            20    0.366397      1.130934     0.501009      0.498991   \n",
      "4            25    0.366775      1.123549     0.503027      0.496973   \n",
      "5            30    0.365763      1.114078     0.501514      0.498486   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.373126   1.124895  0.502018   0.497982  \n",
      "1  0.367632   1.121301  0.502018   0.497982  \n",
      "2  0.362703   1.123997  0.499495   0.500505  \n",
      "3  0.362093   1.119274  0.501514   0.498486  \n",
      "4  0.366749   1.125119  0.502018   0.497982  \n",
      "5  0.367743   1.128701  0.503027   0.496973  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5   0.34801    1.109768   0.513118    0.486882    0.348010   \n",
      "1            10   0.34801    1.109768   0.513118    0.486882    0.348010   \n",
      "2            15   0.34801    1.109768   0.513118    0.486882    0.348010   \n",
      "3            20   0.34801    1.109768   0.513118    0.486882    0.349133   \n",
      "4            25   0.34801    1.109768   0.513118    0.486882    0.349133   \n",
      "5            30   0.34801    1.109768   0.513118    0.486882    0.349133   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0      1.109768     0.513118      0.486882  \n",
      "1      1.109768     0.513118      0.486882  \n",
      "2      1.109768     0.513118      0.486882  \n",
      "3      1.109540     0.513623      0.486377  \n",
      "4      1.109540     0.513623      0.486377  \n",
      "5      1.109540     0.513623      0.486377  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1  rbf_rmse  \\\n",
      "0   0.5    0.34801     1.109768    0.513118     0.486882  0.348904  1.109768   \n",
      "1   1.0    0.34801     1.109768    0.513118     0.486882  0.356650  1.109540   \n",
      "2   1.5    0.34801     1.109768    0.513118     0.486882  0.362872  1.116114   \n",
      "3   2.0    0.34801     1.109768    0.513118     0.486882  0.363996  1.115436   \n",
      "4   2.5    0.34801     1.109768    0.513118     0.486882  0.363308  1.116792   \n",
      "5   3.0    0.34801     1.109768    0.513118     0.486882  0.365719  1.129595   \n",
      "6   4.0    0.34801     1.109768    0.513118     0.486882  0.363703  1.125119   \n",
      "7   5.0    0.34801     1.109768    0.513118     0.486882  0.363467  1.126016   \n",
      "8  10.0    0.34801     1.109768    0.513118     0.486882  0.363117  1.131826   \n",
      "9  20.0    0.34801     1.109768    0.513118     0.486882  0.363117  1.131826   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.513118  0.486882  0.354892   1.111131  0.513623   0.486377       0.34801   \n",
      "1  0.514127  0.485873  0.354410   1.113625  0.512109   0.487891       0.34801   \n",
      "2  0.509082  0.490918  0.355018   1.116340  0.511100   0.488900       0.34801   \n",
      "3  0.508073  0.491927  0.355250   1.116114  0.511604   0.488396       0.34801   \n",
      "4  0.506559  0.493441  0.354064   1.115662  0.511100   0.488900       0.34801   \n",
      "5  0.504036  0.495964  0.353084   1.114984  0.510595   0.489405       0.34801   \n",
      "6  0.502018  0.497982  0.352855   1.115210  0.510091   0.489909       0.34801   \n",
      "7  0.501514  0.498486  0.352855   1.115210  0.510091   0.489909       0.34801   \n",
      "8  0.501009  0.498991  0.352855   1.115210  0.510091   0.489909       0.34801   \n",
      "9  0.501009  0.498991  0.352855   1.115210  0.510091   0.489909       0.34801   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0        1.109768       0.513118        0.486882  \n",
      "1        1.109768       0.513118        0.486882  \n",
      "2        1.109768       0.513118        0.486882  \n",
      "3        1.109768       0.513118        0.486882  \n",
      "4        1.109768       0.513118        0.486882  \n",
      "5        1.109768       0.513118        0.486882  \n",
      "6        1.109768       0.513118        0.486882  \n",
      "7        1.109768       0.513118        0.486882  \n",
      "8        1.109768       0.513118        0.486882  \n",
      "9        1.109768       0.513118        0.486882  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "1      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "2      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "3      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "1       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "2       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "3       1.109768      0.513118       0.486882  0.366894   1.114078  0.508073   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.486882  0.362472   1.108630  0.512109   0.487891  (10, 10, 10)  \n",
      "1   0.486882  0.350107   1.109085  0.512109   0.487891     (5, 5, 5)  \n",
      "2   0.486882  0.348010   1.109768  0.513118   0.486882     (3, 3, 3)  \n",
      "3   0.491927  0.365977   1.125792  0.506054   0.493946  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.349133       1.109540      0.513623       0.486377      0.34801   \n",
      "1     0.348010       1.109768      0.513118       0.486882      0.34801   \n",
      "2     0.348010       1.109768      0.513118       0.486882      0.34801   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0       1.109768      0.513118       0.486882  0.364318   1.134942  0.498991   \n",
      "1       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "2       1.109768      0.513118       0.486882  0.348675   1.109995  0.512614   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.501009  0.367375   1.134942  0.493441   0.506559  lbfgs  \n",
      "1   0.486882  0.348010   1.109768  0.513118   0.486882    sgd  \n",
      "2   0.487386  0.357846   1.117695  0.507064   0.492936   adam  \n",
      "df_NN\n",
      "10\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.134211   4.309600  0.133199   0.866801      0.133664   \n",
      "1    2  0.173025   2.553168  0.239657   0.760343      0.172405   \n",
      "2    3  0.136811   3.237177  0.140767   0.859233      0.135881   \n",
      "3    4  0.127574   3.290279  0.122099   0.877901      0.127604   \n",
      "4    5  0.145165   3.181287  0.140262   0.859738      0.144580   \n",
      "5    6  0.164397   3.125204  0.160949   0.839051      0.163307   \n",
      "6    7  0.148762   3.144197  0.145812   0.854188      0.148228   \n",
      "7    8  0.147251   3.070891  0.146317   0.853683      0.147332   \n",
      "8    9  0.148269   3.100731  0.152876   0.847124      0.148285   \n",
      "9   10  0.149490   3.088993  0.152371   0.847629      0.150751   \n",
      "10  11  0.148574   3.124155  0.153885   0.846115      0.148857   \n",
      "11  12  0.195154   2.324463  0.249243   0.750757      0.195586   \n",
      "12  13  0.196918   2.324572  0.251261   0.748739      0.196559   \n",
      "13  14  0.194905   2.314457  0.252270   0.747730      0.195240   \n",
      "14  15  0.197429   2.316309  0.254793   0.745207      0.197514   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0         4.309600       0.132694        0.867306    0.134211      4.309600   \n",
      "1         2.551982       0.239152        0.760848    0.173025      2.553168   \n",
      "2         3.234916       0.139758        0.860242    0.136811      3.237177   \n",
      "3         3.289665       0.122099        0.877901    0.127574      3.290279   \n",
      "4         3.180256       0.139758        0.860242    0.145165      3.181287   \n",
      "5         3.125850       0.159939        0.840061    0.164397      3.125204   \n",
      "6         3.144758       0.145308        0.854692    0.148762      3.144197   \n",
      "7         3.070891       0.146317        0.853683    0.147251      3.070891   \n",
      "8         3.101625       0.152876        0.847124    0.148269      3.100731   \n",
      "9         3.088584       0.153380        0.846620    0.149490      3.088993   \n",
      "10        3.125043       0.153885        0.846115    0.148574      3.124155   \n",
      "11        2.324680       0.249748        0.750252    0.195154      2.324463   \n",
      "12        2.325548       0.250757        0.749243    0.196918      2.324572   \n",
      "13        2.314893       0.252775        0.747225    0.194905      2.314457   \n",
      "14        2.316962       0.254793        0.745207    0.197429      2.316309   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.133199      0.866801  0.170431    2.650895   0.221998    0.778002  \n",
      "1      0.239657      0.760343  0.150559    2.676089   0.221998    0.778002  \n",
      "2      0.140767      0.859233  0.177714    2.548916   0.207871    0.792129  \n",
      "3      0.122099      0.877901  0.134833    2.642985   0.137235    0.862765  \n",
      "4      0.140262      0.859738  0.140557    2.553860   0.147830    0.852170  \n",
      "5      0.160949      0.839051  0.133202    2.595016   0.141271    0.858729  \n",
      "6      0.145812      0.854188  0.179538    2.410350   0.220484    0.779516  \n",
      "7      0.146317      0.853683  0.185252    2.348218   0.237134    0.762866  \n",
      "8      0.152876      0.847124  0.180352    2.339823   0.226034    0.773966  \n",
      "9      0.152371      0.847629  0.183630    2.331831   0.240666    0.759334  \n",
      "10     0.153885      0.846115  0.185266    2.395863   0.234612    0.765388  \n",
      "11     0.249243      0.750757  0.167647    2.467140   0.238143    0.761857  \n",
      "12     0.251261      0.748739  0.185682    2.387108   0.233098    0.766902  \n",
      "13     0.252270      0.747730  0.169647    2.482329   0.254289    0.745711  \n",
      "14     0.254793      0.745207  0.170746    2.476428   0.246720    0.753280  \n",
      "df_knn\n",
      "          Alpha  F1_score      RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.171068  2.396600  0.271443  0.728557\n",
      "1  1.000000e-04  0.171068  2.396600  0.271443  0.728557\n",
      "2  1.000000e-03  0.171068  2.396600  0.271443  0.728557\n",
      "3  1.000000e-02  0.171068  2.396600  0.271443  0.728557\n",
      "4  1.000000e-01  0.171068  2.396600  0.271443  0.728557\n",
      "5  5.000000e-01  0.170858  2.397021  0.270938  0.729062\n",
      "6  1.000000e+00  0.172074  2.401122  0.277497  0.722503\n",
      "7  2.000000e+00  0.172074  2.401122  0.277497  0.722503\n",
      "8  1.000000e+01  0.173045  2.419439  0.276488  0.723512\n",
      "df_NB\n",
      "          Alpha  F1_score      RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.153477  2.423085  0.281534  0.718466\n",
      "1  1.000000e-04  0.153477  2.423085  0.281534  0.718466\n",
      "2  1.000000e-03  0.153477  2.423085  0.281534  0.718466\n",
      "3  1.000000e-02  0.153477  2.423085  0.281534  0.718466\n",
      "4  1.000000e-01  0.153477  2.423085  0.281534  0.718466\n",
      "5  5.000000e-01  0.153477  2.423085  0.281534  0.718466\n",
      "6  1.000000e+00  0.153477  2.423085  0.281534  0.718466\n",
      "7  2.000000e+00  0.153477  2.423085  0.281534  0.718466\n",
      "8  1.000000e+01  0.150156  2.429428  0.279011  0.720989\n",
      "df_MNB\n",
      "     Var Smooth  F1_score      RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.005810  5.109794  0.028254  0.971746\n",
      "1  1.000000e-04  0.094349  4.401346  0.087286  0.912714\n",
      "2  1.000000e-03  0.168531  3.001429  0.202825  0.797175\n",
      "3  1.000000e-02  0.167042  2.786916  0.208375  0.791625\n",
      "4  1.000000e-01  0.170114  2.577752  0.224016  0.775984\n",
      "5  5.000000e-01  0.173354  2.405007  0.272957  0.727043\n",
      "6  1.000000e+00  0.144981  2.436789  0.282543  0.717457\n",
      "7  2.000000e+00  0.117828  2.459767  0.271948  0.728052\n",
      "8  1.000000e+01  0.115517  2.460690  0.270938  0.729062\n",
      "df_GNB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1      0.151792        2.424646       0.273966        0.726034   \n",
      "1    2      0.152754        2.424542       0.274470        0.725530   \n",
      "2    3      0.154275        2.424334       0.275479        0.724521   \n",
      "3    4      0.157491        2.418396       0.274975        0.725025   \n",
      "4    5      0.157491        2.418396       0.274975        0.725025   \n",
      "5    6      0.157491        2.418396       0.274975        0.725025   \n",
      "6    7      0.157491        2.418396       0.274975        0.725025   \n",
      "7    8      0.157491        2.418396       0.274975        0.725025   \n",
      "8    9      0.157491        2.418396       0.274975        0.725025   \n",
      "9   10      0.157491        2.418396       0.274975        0.725025   \n",
      "10  11      0.157491        2.418396       0.274975        0.725025   \n",
      "11  12      0.157491        2.418396       0.274975        0.725025   \n",
      "12  13      0.157491        2.418396       0.274975        0.725025   \n",
      "13  14      0.157491        2.418396       0.274975        0.725025   \n",
      "14  15      0.157491        2.418396       0.274975        0.725025   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.156049        2.418604       0.273966        0.726034  0.156049   \n",
      "1       0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "2       0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "3       0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "4       0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "5       0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "6       0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "7       0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "8       0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "9       0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "10      0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "11      0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "12      0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "13      0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "14      0.156129        2.417457       0.273966        0.726034  0.156129   \n",
      "\n",
      "    sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0   2.418604  0.273966  0.726034  0.156049    2.418604   0.273966    0.726034  \n",
      "1   2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "2   2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "3   2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "4   2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "5   2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "6   2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "7   2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "8   2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "9   2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "10  2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "11  2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "12  2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "13  2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "14  2.417457  0.273966  0.726034  0.156129    2.417457   0.273966    0.726034  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.146861      2.429220     0.277497      0.722503  0.146861   \n",
      "1           2    0.146861      2.429220     0.277497      0.722503  0.137329   \n",
      "2           3    0.143000      2.429116     0.278002      0.721998  0.153939   \n",
      "3           4    0.140618      2.430154     0.276488      0.723512  0.152344   \n",
      "4           5    0.146844      2.439790     0.272957      0.727043  0.148124   \n",
      "5           6    0.167475      2.420168     0.276488      0.723512  0.163321   \n",
      "6           7    0.176279      2.430570     0.271948      0.728052  0.160740   \n",
      "7           8    0.179692      2.427142     0.276488      0.723512  0.179633   \n",
      "8           9    0.184035      2.429324     0.274470      0.725530  0.184602   \n",
      "9          10    0.185717      2.420794     0.274470      0.725530  0.183387   \n",
      "10         11    0.185112      2.423918     0.273966      0.726034  0.184297   \n",
      "11         12    0.184841      2.424022     0.273461      0.726539  0.184439   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0    2.429220  0.277497   0.722503  \n",
      "1    2.437928  0.276488   0.723512  \n",
      "2    2.418187  0.278507   0.721493  \n",
      "3    2.425583  0.277497   0.722503  \n",
      "4    2.441237  0.278002   0.721998  \n",
      "5    2.422565  0.280020   0.719980  \n",
      "6    2.437100  0.279516   0.720484  \n",
      "7    2.419021  0.272957   0.727043  \n",
      "8    2.418083  0.275479   0.724521  \n",
      "9    2.428077  0.272957   0.727043  \n",
      "10   2.418291  0.273966   0.726034  \n",
      "11   2.422148  0.273966   0.726034  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.183853      2.424959     0.271443      0.728557   \n",
      "1            10    0.179830      2.417144     0.272957      0.727043   \n",
      "2            15    0.176640      2.405636     0.263875      0.736125   \n",
      "3            20    0.183526      2.404797     0.267911      0.732089   \n",
      "4            25    0.187883      2.410141     0.274470      0.725530   \n",
      "5            30    0.187016      2.407942     0.275479      0.724521   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.187424   2.411815  0.271948   0.728052  \n",
      "1  0.185253   2.405846  0.267911   0.732089  \n",
      "2  0.181982   2.406684  0.274470   0.725530  \n",
      "3  0.185464   2.426934  0.272452   0.727548  \n",
      "4  0.181934   2.423918  0.274975   0.725025  \n",
      "5  0.178702   2.417457  0.263875   0.736125  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.112829    2.144385   0.235621    0.764379    0.136931   \n",
      "1            10  0.131381    2.428493   0.270434    0.729566    0.151866   \n",
      "2            15  0.147502    2.428285   0.276993    0.723007    0.152227   \n",
      "3            20  0.135499    2.425063   0.271443    0.728557    0.149830   \n",
      "4            25  0.165011    2.368222   0.267407    0.732593    0.152766   \n",
      "5            30  0.164695    2.364384   0.261857    0.738143    0.154918   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0      2.438342     0.276993      0.723007  \n",
      "1      2.432333     0.281534      0.718466  \n",
      "2      2.421419     0.271443      0.728557  \n",
      "3      2.425375     0.272452      0.727548  \n",
      "4      2.418604     0.272452      0.727548  \n",
      "5      2.418813     0.272957      0.727043  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1  rbf_rmse  \\\n",
      "0   0.5   0.147985     2.424854    0.270938     0.729062  0.163777  2.405426   \n",
      "1   1.0   0.148704     2.424959    0.270434     0.729566  0.174927  2.392913   \n",
      "2   1.5   0.148704     2.424959    0.270434     0.729566  0.182980  2.393335   \n",
      "3   2.0   0.148704     2.424959    0.270434     0.729566  0.184407  2.393546   \n",
      "4   2.5   0.148704     2.424959    0.270434     0.729566  0.184325  2.394073   \n",
      "5   3.0   0.148704     2.424959    0.270434     0.729566  0.183642  2.408361   \n",
      "6   4.0   0.148704     2.424959    0.270434     0.729566  0.182324  2.414011   \n",
      "7   5.0   0.148704     2.424959    0.270434     0.729566  0.181886  2.414951   \n",
      "8  10.0   0.148704     2.424959    0.270434     0.729566  0.182523  2.414533   \n",
      "9  20.0   0.148704     2.424959    0.270434     0.729566  0.181829  2.418604   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.274470  0.725530  0.180989   2.398389  0.273461   0.726539      0.152966   \n",
      "1  0.276488  0.723512  0.181911   2.408361  0.280525   0.719475      0.152966   \n",
      "2  0.278002  0.721998  0.182233   2.411606  0.279011   0.720989      0.152966   \n",
      "3  0.278002  0.721998  0.183254   2.409094  0.279516   0.720484      0.152966   \n",
      "4  0.277497  0.722503  0.181948   2.408989  0.278507   0.721493      0.152966   \n",
      "5  0.275984  0.724016  0.180644   2.407732  0.278507   0.721493      0.152966   \n",
      "6  0.274470  0.725530  0.180593   2.406894  0.278507   0.721493      0.152966   \n",
      "7  0.273966  0.726034  0.180447   2.415682  0.278002   0.721998      0.152966   \n",
      "8  0.273461  0.726539  0.181275   2.420689  0.278507   0.721493      0.152966   \n",
      "9  0.272957  0.727043  0.181275   2.420689  0.278507   0.721493      0.152966   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0        2.423606       0.275479        0.724521  \n",
      "1        2.423606       0.275479        0.724521  \n",
      "2        2.423606       0.275479        0.724521  \n",
      "3        2.423606       0.275479        0.724521  \n",
      "4        2.423606       0.275479        0.724521  \n",
      "5        2.423606       0.275479        0.724521  \n",
      "6        2.423606       0.275479        0.724521  \n",
      "7        2.423606       0.275479        0.724521  \n",
      "8        2.423606       0.275479        0.724521  \n",
      "9        2.423606       0.275479        0.724521  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.152175       2.422669      0.271948       0.728052     0.115517   \n",
      "1     0.115793       2.456586      0.270938       0.729062     0.115517   \n",
      "2     0.115517       2.460690      0.270938       0.729062     0.115517   \n",
      "3     0.152500       2.428181      0.273966       0.726034     0.115517   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        2.46069      0.270938       0.729062  0.176151   2.394494  0.272957   \n",
      "1        2.46069      0.270938       0.729062  0.133028   2.439790  0.266398   \n",
      "2        2.46069      0.270938       0.729062  0.115517   2.460690  0.270938   \n",
      "3        2.46069      0.270938       0.729062  0.172316   2.402383  0.270938   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.727043  0.158977   2.434096  0.277497   0.722503  (10, 10, 10)  \n",
      "1   0.733602  0.115517   2.460690  0.270938   0.729062     (5, 5, 5)  \n",
      "2   0.729062  0.133070   2.446811  0.261857   0.738143     (3, 3, 3)  \n",
      "3   0.729062  0.186661   2.434821  0.278507   0.721493  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.152798       2.424542      0.274470       0.725530     0.115517   \n",
      "1     0.132149       2.444644      0.276488       0.723512     0.115517   \n",
      "2     0.154325       2.427870      0.275479       0.724521     0.115517   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        2.46069      0.270938       0.729062  0.179276   2.441237  0.266398   \n",
      "1        2.46069      0.270938       0.729062  0.115517   2.460690  0.270938   \n",
      "2        2.46069      0.270938       0.729062  0.158893   2.418917  0.274975   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.733602  0.146361   2.443716  0.274975   0.725025  lbfgs  \n",
      "1   0.729062  0.115270   2.460895  0.269929   0.730071    sgd  \n",
      "2   0.725025  0.158062   2.428493  0.272957   0.727043   adam  \n",
      "df_NN\n",
      "100\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.014051  45.461486  0.027750   0.972250      0.014666   \n",
      "1    2  0.012165  25.888753  0.028759   0.971241      0.012757   \n",
      "2    3  0.010911  33.224089  0.014632   0.985368      0.011634   \n",
      "3    4  0.009414  34.217275  0.013118   0.986882      0.010146   \n",
      "4    5  0.007191  34.963265  0.011100   0.988900      0.008040   \n",
      "5    6  0.008540  35.407039  0.011100   0.988900      0.009221   \n",
      "6    7  0.008617  34.748701  0.013118   0.986882      0.008885   \n",
      "7    8  0.009817  34.575069  0.012109   0.987891      0.010047   \n",
      "8    9  0.009725  46.832710  0.024218   0.975782      0.009969   \n",
      "9   10  0.009301  47.001573  0.023713   0.976287      0.009517   \n",
      "10  11  0.008482  47.144110  0.022704   0.977296      0.009169   \n",
      "11  12  0.009918  46.797355  0.024218   0.975782      0.010597   \n",
      "12  13  0.010363  46.218387  0.024218   0.975782      0.011020   \n",
      "13  14  0.009355  26.017798  0.015641   0.984359      0.010056   \n",
      "14  15  0.010145  25.642383  0.016145   0.983855      0.010865   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0        45.461653       0.028254        0.971746    0.014051     45.461486   \n",
      "1        25.876160       0.029263        0.970737    0.012165     25.888753   \n",
      "2        33.210980       0.015136        0.984864    0.010911     33.224089   \n",
      "3        34.197680       0.013623        0.986377    0.009414     34.217275   \n",
      "4        34.964448       0.011604        0.988396    0.007191     34.963265   \n",
      "5        35.405051       0.011604        0.988396    0.008540     35.407039   \n",
      "6        34.742073       0.013623        0.986377    0.008617     34.748701   \n",
      "7        34.575237       0.012614        0.987386    0.009817     34.575069   \n",
      "8        46.837875       0.024723        0.975277    0.009725     46.832710   \n",
      "9        47.001723       0.024218        0.975782    0.009301     47.001573   \n",
      "10       47.140054       0.023209        0.976791    0.008482     47.144110   \n",
      "11       46.789915       0.024723        0.975277    0.009918     46.797355   \n",
      "12       46.216640       0.024723        0.975277    0.010363     46.218387   \n",
      "13       26.019670       0.016145        0.983855    0.009355     26.017798   \n",
      "14       25.639943       0.016650        0.983350    0.010145     25.642383   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.027750      0.972250  0.015596   27.176767   0.028759    0.971241  \n",
      "1      0.028759      0.971241  0.012922   27.348021   0.027750    0.972250  \n",
      "2      0.014632      0.985368  0.010148   27.570074   0.026741    0.973259  \n",
      "3      0.013118      0.986882  0.010408   28.001451   0.016145    0.983855  \n",
      "4      0.011100      0.988900  0.011853   28.911815   0.018163    0.981837  \n",
      "5      0.011100      0.988900  0.010811   28.259447   0.018163    0.981837  \n",
      "6      0.013118      0.986882  0.008308   28.360543   0.015641    0.984359  \n",
      "7      0.012109      0.987891  0.005761   30.482762   0.012109    0.987891  \n",
      "8      0.024218      0.975782  0.006380   30.244663   0.011604    0.988396  \n",
      "9      0.023713      0.976287  0.005457   34.364124   0.005550    0.994450  \n",
      "10     0.022704      0.977296  0.006063   33.595602   0.007568    0.992432  \n",
      "11     0.024218      0.975782  0.007379   28.580387   0.012109    0.987891  \n",
      "12     0.024218      0.975782  0.007061   28.405152   0.011604    0.988396  \n",
      "13     0.015641      0.984359  0.006427   28.449585   0.011100    0.988900  \n",
      "14     0.016145      0.983855  0.007783   27.826740   0.013118    0.986882  \n",
      "df_knn\n",
      "          Alpha  F1_score       RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.009376  23.675755  0.024218  0.975782\n",
      "1  1.000000e-04  0.009376  23.675755  0.024218  0.975782\n",
      "2  1.000000e-03  0.009376  23.675755  0.024218  0.975782\n",
      "3  1.000000e-02  0.009376  23.675755  0.024218  0.975782\n",
      "4  1.000000e-01  0.008436  23.578315  0.023713  0.976287\n",
      "5  5.000000e-01  0.008438  23.617164  0.023713  0.976287\n",
      "6  1.000000e+00  0.011456  23.721198  0.026741  0.973259\n",
      "7  2.000000e+00  0.010069  23.459188  0.026236  0.973764\n",
      "8  1.000000e+01  0.009292  23.041324  0.026236  0.973764\n",
      "df_NB\n",
      "          Alpha  F1_score       RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.010411  22.956634  0.026236  0.973764\n",
      "1  1.000000e-04  0.010411  22.956634  0.026236  0.973764\n",
      "2  1.000000e-03  0.010411  22.956634  0.026236  0.973764\n",
      "3  1.000000e-02  0.010411  22.956634  0.026236  0.973764\n",
      "4  1.000000e-01  0.010411  22.956634  0.026236  0.973764\n",
      "5  5.000000e-01  0.010391  22.968280  0.026236  0.973764\n",
      "6  1.000000e+00  0.009541  23.006887  0.025732  0.974268\n",
      "7  2.000000e+00  0.008968  22.946577  0.025227  0.974773\n",
      "8  1.000000e+01  0.007565  22.809813  0.024723  0.975277\n",
      "df_MNB\n",
      "     Var Smooth  F1_score       RMSE       ACC      HAMM\n",
      "0  1.000000e-10  0.000102  53.702764  0.000505  0.999495\n",
      "1  1.000000e-04  0.000102  53.720668  0.000505  0.999495\n",
      "2  1.000000e-03  0.000102  53.699283  0.000505  0.999495\n",
      "3  1.000000e-02  0.000109  53.672734  0.000505  0.999495\n",
      "4  1.000000e-01  0.000965  52.537090  0.001514  0.998486\n",
      "5  5.000000e-01  0.006962  44.472647  0.009586  0.990414\n",
      "6  1.000000e+00  0.007657  22.936868  0.026741  0.973259\n",
      "7  2.000000e+00  0.005242  22.689209  0.026741  0.973259\n",
      "8  1.000000e+01  0.002511  22.541765  0.026236  0.973764\n",
      "df_GNB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1      0.011284       23.122071       0.027750        0.972250   \n",
      "1    2      0.012571       23.132837       0.028254        0.971746   \n",
      "2    3      0.012364       23.146443       0.027750        0.972250   \n",
      "3    4      0.012619       23.147053       0.028254        0.971746   \n",
      "4    5      0.011732       23.150203       0.027750        0.972250   \n",
      "5    6      0.011732       23.150203       0.027750        0.972250   \n",
      "6    7      0.011732       23.150203       0.027750        0.972250   \n",
      "7    8      0.011732       23.152164       0.027750        0.972250   \n",
      "8    9      0.011772       23.201961       0.027750        0.972250   \n",
      "9   10      0.011772       23.209092       0.027750        0.972250   \n",
      "10  11      0.011784       23.230615       0.027750        0.972250   \n",
      "11  12      0.011790       23.251889       0.027750        0.972250   \n",
      "12  13      0.012385       23.290102       0.028254        0.971746   \n",
      "13  14      0.012385       23.290102       0.028254        0.971746   \n",
      "14  15      0.012385       23.290102       0.028254        0.971746   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.012717       23.027722       0.028759        0.971241  0.012717   \n",
      "1       0.012619       23.045046       0.028254        0.971746  0.012619   \n",
      "2       0.012660       23.102795       0.028254        0.971746  0.012660   \n",
      "3       0.011781       23.117532       0.027750        0.972250  0.011781   \n",
      "4       0.012436       23.176722       0.028254        0.971746  0.012436   \n",
      "5       0.012436       23.178376       0.028254        0.971746  0.012436   \n",
      "6       0.012462       23.244695       0.028254        0.971746  0.012462   \n",
      "7       0.012150       23.278704       0.027245        0.972755  0.012150   \n",
      "8       0.012150       23.285812       0.027245        0.972755  0.012150   \n",
      "9       0.012150       23.285812       0.027245        0.972755  0.012150   \n",
      "10      0.012171       23.312578       0.027245        0.972755  0.012171   \n",
      "11      0.012187       23.300639       0.027245        0.972755  0.012177   \n",
      "12      0.012187       23.317144       0.027245        0.972755  0.012187   \n",
      "13      0.012187       23.317144       0.027245        0.972755  0.012187   \n",
      "14      0.012187       23.305586       0.027245        0.972755  0.012187   \n",
      "\n",
      "     sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0   23.027722  0.028759  0.971241  0.012717   23.027722   0.028759    0.971241  \n",
      "1   23.045046  0.028254  0.971746  0.012619   23.045046   0.028254    0.971746  \n",
      "2   23.102795  0.028254  0.971746  0.012660   23.102795   0.028254    0.971746  \n",
      "3   23.117532  0.027750  0.972250  0.011781   23.117532   0.027750    0.972250  \n",
      "4   23.176722  0.028254  0.971746  0.012450   23.175764   0.028254    0.971746  \n",
      "5   23.178376  0.028254  0.971746  0.012436   23.185134   0.028254    0.971746  \n",
      "6   23.244695  0.028254  0.971746  0.012193   23.253549   0.027245    0.972755  \n",
      "7   23.278704  0.027245  0.972755  0.012213   23.280958   0.027245    0.972755  \n",
      "8   23.285812  0.027245  0.972755  0.012213   23.280958   0.027245    0.972755  \n",
      "9   23.285812  0.027245  0.972755  0.012150   23.285812   0.027245    0.972755  \n",
      "10  23.312578  0.027245  0.972755  0.012234   23.307729   0.027245    0.972755  \n",
      "11  23.329020  0.027245  0.972755  0.012177   23.345505   0.027245    0.972755  \n",
      "12  23.317144  0.027245  0.972755  0.012239   23.340664   0.027245    0.972755  \n",
      "13  23.317144  0.027245  0.972755  0.012177   23.345505   0.027245    0.972755  \n",
      "14  23.305586  0.027245  0.972755  0.012187   23.317144   0.027245    0.972755  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.003108     22.812092     0.033300      0.966700  0.003439   \n",
      "1           2    0.004617     22.991761     0.034309      0.965691  0.005054   \n",
      "2           3    0.005380     23.081973     0.033804      0.966196  0.006457   \n",
      "3           4    0.008957     23.235490     0.033300      0.966700  0.005422   \n",
      "4           5    0.010107     22.963117     0.029768      0.970232  0.003886   \n",
      "5           6    0.006656     23.337280     0.023713      0.976287  0.004851   \n",
      "6           7    0.009915     23.531481     0.025227      0.974773  0.005971   \n",
      "7           8    0.010300     23.769294     0.024723      0.975277  0.008055   \n",
      "8           9    0.012956     23.953643     0.026236      0.973764  0.008903   \n",
      "9          10    0.013819     23.900061     0.026741      0.973259  0.010216   \n",
      "10         11    0.013806     23.921827     0.026741      0.973259  0.012828   \n",
      "11         12    0.013806     23.921827     0.026741      0.973259  0.012891   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0   22.701147  0.027750   0.972250  \n",
      "1   23.330123  0.029768   0.970232  \n",
      "2   23.297878  0.027750   0.972250  \n",
      "3   23.396982  0.025732   0.974268  \n",
      "4   23.081646  0.025732   0.974268  \n",
      "5   23.249122  0.023713   0.976287  \n",
      "6   23.282183  0.023209   0.976791  \n",
      "7   23.359354  0.024723   0.975277  \n",
      "8   23.550791  0.024218   0.975782  \n",
      "9   23.939842  0.024218   0.975782  \n",
      "10  23.879491  0.026236   0.973764  \n",
      "11  23.923862  0.026236   0.973764  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.016512     23.725069     0.030272      0.969728   \n",
      "1            10    0.008495     23.824810     0.021695      0.978305   \n",
      "2            15    0.015539     23.564980     0.028254      0.971746   \n",
      "3            20    0.014980     25.707654     0.027750      0.972250   \n",
      "4            25    0.012288     24.669030     0.025732      0.974268   \n",
      "5            30    0.012461     24.037213     0.024723      0.975277   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.011809  24.148799  0.025732   0.974268  \n",
      "1  0.013659  26.341984  0.027245   0.972755  \n",
      "2  0.014758  24.656510  0.028254   0.971746  \n",
      "3  0.014888  24.257490  0.028254   0.971746  \n",
      "4  0.012071  24.029676  0.025227   0.974773  \n",
      "5  0.014565  23.410671  0.027245   0.972755  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.002428   24.232393   0.025227    0.974773    0.003729   \n",
      "1            10  0.002428   24.232393   0.025227    0.974773    0.007214   \n",
      "2            15  0.002428   24.232393   0.025227    0.974773    0.003925   \n",
      "3            20  0.002428   24.232393   0.025227    0.974773    0.003941   \n",
      "4            25  0.002428   24.232393   0.025227    0.974773    0.003551   \n",
      "5            30  0.002428   24.232393   0.025227    0.974773    0.003943   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0     23.175492     0.022704      0.977296  \n",
      "1     26.132135     0.023209      0.976791  \n",
      "2     29.470290     0.018668      0.981332  \n",
      "3     30.330404     0.018668      0.981332  \n",
      "4     32.658432     0.018163      0.981837  \n",
      "5     30.868500     0.018668      0.981332  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1   rbf_rmse  \\\n",
      "0   0.5   0.008186    23.041040    0.027750     0.972250  0.006776  23.073185   \n",
      "1   1.0   0.009812    23.098591    0.027245     0.972755  0.010626  23.445839   \n",
      "2   1.5   0.010005    23.147598    0.026236     0.973764  0.013380  23.297564   \n",
      "3   2.0   0.010298    22.957975    0.026236     0.973764  0.012723  24.214335   \n",
      "4   2.5   0.010685    23.091972    0.025732     0.974268  0.012133  24.179054   \n",
      "5   3.0   0.010092    22.954744    0.026236     0.973764  0.012731  24.207885   \n",
      "6   4.0   0.009668    22.998552    0.025732     0.974268  0.015505  24.172010   \n",
      "7   5.0   0.010405    22.953436    0.025732     0.974268  0.015759  24.139374   \n",
      "8  10.0   0.009484    23.032290    0.025227     0.974773  0.014971  24.101377   \n",
      "9  20.0   0.009721    23.024950    0.025732     0.974268  0.014971  24.101377   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.024723  0.975277  0.013032  23.191129  0.027750   0.972250        0.0115   \n",
      "1  0.026741  0.973259  0.012169  23.286213  0.026236   0.973764        0.0115   \n",
      "2  0.027245  0.972755  0.012549  23.433742  0.026236   0.973764        0.0115   \n",
      "3  0.026741  0.973259  0.013488  24.236651  0.026236   0.973764        0.0115   \n",
      "4  0.026236  0.973764  0.013439  24.177812  0.026236   0.973764        0.0115   \n",
      "5  0.026741  0.973259  0.014563  24.110649  0.027245   0.972755        0.0115   \n",
      "6  0.028759  0.971241  0.014338  23.328912  0.027245   0.972755        0.0115   \n",
      "7  0.029263  0.970737  0.014427  23.339410  0.027245   0.972755        0.0115   \n",
      "8  0.028759  0.971241  0.014581  23.358242  0.027750   0.972250        0.0115   \n",
      "9  0.028759  0.971241  0.014581  23.358242  0.027750   0.972250        0.0115   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0       22.997708       0.028254        0.971746  \n",
      "1       22.997708       0.028254        0.971746  \n",
      "2       23.015778       0.028254        0.971746  \n",
      "3       23.015778       0.028254        0.971746  \n",
      "4       23.015778       0.028254        0.971746  \n",
      "5       23.015778       0.028254        0.971746  \n",
      "6       23.015778       0.028254        0.971746  \n",
      "7       23.015778       0.028254        0.971746  \n",
      "8       23.015778       0.028254        0.971746  \n",
      "9       23.015778       0.028254        0.971746  \n",
      "df_SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.009865      23.387945      0.026236       0.973764     0.001499   \n",
      "1     0.009772      23.358987      0.027750       0.972250     0.001499   \n",
      "2     0.005837      22.630048      0.029768       0.970232     0.001499   \n",
      "3     0.012301      23.436874      0.027245       0.972755     0.001499   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0      22.486065       0.02775        0.97225  0.013939  25.409472  0.031282   \n",
      "1      22.486065       0.02775        0.97225  0.009228  23.277642  0.036831   \n",
      "2      22.486065       0.02775        0.97225  0.001500  22.486603  0.027750   \n",
      "3      22.486065       0.02775        0.97225  0.010805  25.393552  0.024723   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.968718  0.010676  25.641261  0.025732   0.974268  (10, 10, 10)  \n",
      "1   0.963169  0.010299  29.190188  0.029768   0.970232     (5, 5, 5)  \n",
      "2   0.972250  0.002314  22.628989  0.027750   0.972250     (3, 3, 3)  \n",
      "3   0.975277  0.013769  23.872264  0.026236   0.973764  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.013483      24.005854      0.027750       0.972250     0.001499   \n",
      "1     0.005177      22.914475      0.025732       0.974268     0.001499   \n",
      "2     0.012558      23.367701      0.029768       0.970232     0.001499   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0      22.486065       0.02775        0.97225  0.011073  24.041001  0.025227   \n",
      "1      22.486065       0.02775        0.97225  0.002495  22.523169  0.027750   \n",
      "2      22.486065       0.02775        0.97225  0.009488  24.092123  0.027245   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.974773  0.008000  24.128231  0.025732   0.974268  lbfgs  \n",
      "1   0.972250  0.004519  22.980589  0.032795   0.967205    sgd  \n",
      "2   0.972755  0.010828  23.947755  0.025732   0.974268   adam  \n",
      "df_NN\n"
     ]
    }
   ],
   "source": [
    "scale_list = [2, 5, 10, 100]\n",
    "file_name = \"model_summary_baseline_final.xlsx\"\n",
    "for scale in scale_list:\n",
    "    print(scale)\n",
    "    Y_train, Y_dev = assign_y(scale)\n",
    "    df_knn = knn_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_NB = NB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_MNB = MNB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_GNB = GNB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_logR = LogR_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_DT = DT_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_RF = RF_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_AdaB = AdaB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_SVM = SVM_models(train_data, Y_train, dev_data)\n",
    "    df_NN1 = NN_models(train_data, Y_train, dev_data, Y_dev, \"L\")\n",
    "    df_NN2 = NN_models(train_data, Y_train, dev_data, Y_dev, \"S\")\n",
    "\n",
    "    wrt_excel(file_name, \"knn-\"+str(scale), df_knn)\n",
    "    wrt_excel(file_name, \"NB-\"+str(scale), df_NB)    \n",
    "    wrt_excel(file_name, \"MNB-\"+str(scale), df_MNB)\n",
    "    wrt_excel(file_name, \"GNB-\"+str(scale), df_GNB)\n",
    "    wrt_excel(file_name, \"logR-\"+str(scale), df_logR)\n",
    "    wrt_excel(file_name, \"DT-\"+str(scale), df_DT)\n",
    "    wrt_excel(file_name, \"RF-\"+str(scale), df_RF)\n",
    "    wrt_excel(file_name, \"AdaB-\"+str(scale), df_AdaB)\n",
    "    wrt_excel(file_name, \"SVM-\"+str(scale), df_SVM)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"L\", df_NN1)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"S\", df_NN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 7 components > IN ADDITION TO ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_pca = 7\n",
    "random_state = 0\n",
    "\n",
    "pca = PCA(n_components=components_pca, random_state=random_state)\n",
    "pca.fit(train_data)\n",
    "\n",
    "# overwriting train_data and dev_data to be the pca object - should do this in a cleaner way to preserve it but giving this a shot\n",
    "train_data1 = pca.transform(train_data)\n",
    "dev_data1 = pca.transform(dev_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.675140   0.538151  0.710394   0.289606      0.675140   \n",
      "1    2  0.689018   0.475431  0.773966   0.226034      0.689018   \n",
      "2    3  0.677462   0.530122  0.718971   0.281029      0.677462   \n",
      "3    4  0.688942   0.473836  0.775479   0.224521      0.688942   \n",
      "4    5  0.678516   0.530122  0.718971   0.281029      0.678516   \n",
      "5    6  0.689465   0.472770  0.776488   0.223512      0.689465   \n",
      "6    7  0.681432   0.521486  0.728052   0.271948      0.681432   \n",
      "7    8  0.681608   0.515648  0.734107   0.265893      0.681608   \n",
      "8    9  0.681608   0.515648  0.734107   0.265893      0.681608   \n",
      "9   10  0.686968   0.468482  0.780525   0.219475      0.686968   \n",
      "10  11  0.686895   0.470631  0.778507   0.221493      0.686895   \n",
      "11  12  0.686895   0.470631  0.778507   0.221493      0.686895   \n",
      "12  13  0.686895   0.470631  0.778507   0.221493      0.686895   \n",
      "13  14  0.686968   0.468482  0.780525   0.219475      0.686968   \n",
      "14  15  0.686968   0.468482  0.780525   0.219475      0.686968   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0         0.538151       0.710394        0.289606    0.675140      0.538151   \n",
      "1         0.475431       0.773966        0.226034    0.689018      0.475431   \n",
      "2         0.530122       0.718971        0.281029    0.677462      0.530122   \n",
      "3         0.473836       0.775479        0.224521    0.688942      0.473836   \n",
      "4         0.530122       0.718971        0.281029    0.678516      0.530122   \n",
      "5         0.472770       0.776488        0.223512    0.689465      0.472770   \n",
      "6         0.521486       0.728052        0.271948    0.681432      0.521486   \n",
      "7         0.515648       0.734107        0.265893    0.681608      0.515648   \n",
      "8         0.515648       0.734107        0.265893    0.681608      0.515648   \n",
      "9         0.468482       0.780525        0.219475    0.686968      0.468482   \n",
      "10        0.470631       0.778507        0.221493    0.686895      0.470631   \n",
      "11        0.470631       0.778507        0.221493    0.686895      0.470631   \n",
      "12        0.470631       0.778507        0.221493    0.686895      0.470631   \n",
      "13        0.468482       0.780525        0.219475    0.686968      0.468482   \n",
      "14        0.468482       0.780525        0.219475    0.686968      0.468482   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.710394      0.289606  0.692514    0.498737   0.751261    0.248739  \n",
      "1      0.773966      0.226034  0.690989    0.481232   0.768416    0.231584  \n",
      "2      0.718971      0.281029  0.691544    0.485927   0.763875    0.236125  \n",
      "3      0.775479      0.224521  0.688322    0.469558   0.779516    0.220484  \n",
      "4      0.718971      0.281029  0.694534    0.469558   0.779516    0.220484  \n",
      "5      0.776488      0.223512  0.687904    0.468482   0.780525    0.219475  \n",
      "6      0.728052      0.271948  0.692454    0.486964   0.762866    0.237134  \n",
      "7      0.734107      0.265893  0.686968    0.468482   0.780525    0.219475  \n",
      "8      0.734107      0.265893  0.686968    0.468482   0.780525    0.219475  \n",
      "9      0.780525      0.219475  0.686968    0.468482   0.780525    0.219475  \n",
      "10     0.778507      0.221493  0.686968    0.468482   0.780525    0.219475  \n",
      "11     0.778507      0.221493  0.686968    0.468482   0.780525    0.219475  \n",
      "12     0.778507      0.221493  0.686968    0.468482   0.780525    0.219475  \n",
      "13     0.780525      0.219475  0.686968    0.468482   0.780525    0.219475  \n",
      "14     0.780525      0.219475  0.686968    0.468482   0.780525    0.219475  \n",
      "df_knn\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1      0.688462         0.46524       0.783552        0.216448   \n",
      "1    2      0.688462         0.46524       0.783552        0.216448   \n",
      "2    3      0.688462         0.46524       0.783552        0.216448   \n",
      "3    4      0.688462         0.46524       0.783552        0.216448   \n",
      "4    5      0.688462         0.46524       0.783552        0.216448   \n",
      "5    6      0.688462         0.46524       0.783552        0.216448   \n",
      "6    7      0.688462         0.46524       0.783552        0.216448   \n",
      "7    8      0.688462         0.46524       0.783552        0.216448   \n",
      "8    9      0.688462         0.46524       0.783552        0.216448   \n",
      "9   10      0.688462         0.46524       0.783552        0.216448   \n",
      "10  11      0.688462         0.46524       0.783552        0.216448   \n",
      "11  12      0.688462         0.46524       0.783552        0.216448   \n",
      "12  13      0.688462         0.46524       0.783552        0.216448   \n",
      "13  14      0.688462         0.46524       0.783552        0.216448   \n",
      "14  15      0.688462         0.46524       0.783552        0.216448   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "1       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "2       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "3       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "4       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "5       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "6       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "7       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "8       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "9       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "10      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "11      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "12      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "13      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "14      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "\n",
      "    sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "1    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "2    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "3    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "4    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "5    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "6    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "7    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "8    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "9    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "10   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "11   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "12   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "13   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "14   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.688462      0.465240     0.783552      0.216448  0.688462   \n",
      "1           2    0.688462      0.465240     0.783552      0.216448  0.688462   \n",
      "2           3    0.688462      0.465240     0.783552      0.216448  0.688462   \n",
      "3           4    0.688462      0.465240     0.783552      0.216448  0.688213   \n",
      "4           5    0.688462      0.465240     0.783552      0.216448  0.688213   \n",
      "5           6    0.688462      0.465240     0.783552      0.216448  0.688213   \n",
      "6           7    0.692601      0.466323     0.782543      0.217457  0.688213   \n",
      "7           8    0.690607      0.464697     0.784057      0.215943  0.688213   \n",
      "8           9    0.690354      0.465240     0.783552      0.216448  0.687715   \n",
      "9          10    0.690517      0.466864     0.782038      0.217962  0.687217   \n",
      "10         11    0.689593      0.466864     0.782038      0.217962  0.686895   \n",
      "11         12    0.689339      0.467404     0.781534      0.218466  0.686390   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0    0.465240  0.783552   0.216448  \n",
      "1    0.465240  0.783552   0.216448  \n",
      "2    0.465240  0.783552   0.216448  \n",
      "3    0.465782  0.783047   0.216953  \n",
      "4    0.465782  0.783047   0.216953  \n",
      "5    0.465782  0.783047   0.216953  \n",
      "6    0.465782  0.783047   0.216953  \n",
      "7    0.465782  0.783047   0.216953  \n",
      "8    0.466864  0.782038   0.217962  \n",
      "9    0.467943  0.781029   0.218971  \n",
      "10   0.470631  0.778507   0.221493  \n",
      "11   0.471702  0.777497   0.222503  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.688978      0.470095     0.779011      0.220989   \n",
      "1            10    0.688156      0.467943     0.781029      0.218971   \n",
      "2            15    0.688407      0.467404     0.781534      0.218466   \n",
      "3            20    0.689748      0.468482     0.780525      0.219475   \n",
      "4            25    0.689235      0.469558     0.779516      0.220484   \n",
      "5            30    0.688067      0.470095     0.779011      0.220989   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.687400   0.469558  0.779516   0.220484  \n",
      "1  0.691819   0.467943  0.781029   0.218971  \n",
      "2  0.687813   0.470631  0.778507   0.221493  \n",
      "3  0.690005   0.467943  0.781029   0.218971  \n",
      "4  0.688831   0.468482  0.780525   0.219475  \n",
      "5  0.686469   0.469558  0.779516   0.220484  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "1            10  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "2            15  0.688462     0.46524   0.783552    0.216448    0.687715   \n",
      "3            20  0.688462     0.46524   0.783552    0.216448    0.687715   \n",
      "4            25  0.688462     0.46524   0.783552    0.216448    0.687715   \n",
      "5            30  0.688462     0.46524   0.783552    0.216448    0.688910   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0      0.465240     0.783552      0.216448  \n",
      "1      0.465240     0.783552      0.216448  \n",
      "2      0.466864     0.782038      0.217962  \n",
      "3      0.466864     0.782038      0.217962  \n",
      "4      0.466864     0.782038      0.217962  \n",
      "5      0.466323     0.782543      0.217457  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1  rbf_rmse  \\\n",
      "0   0.5   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "1   1.0   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "2   1.5   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "3   2.0   0.688462      0.46524    0.783552     0.216448  0.688213  0.465782   \n",
      "4   2.5   0.688462      0.46524    0.783552     0.216448  0.688213  0.465782   \n",
      "5   3.0   0.688462      0.46524    0.783552     0.216448  0.688213  0.465782   \n",
      "6   4.0   0.688462      0.46524    0.783552     0.216448  0.688910  0.466323   \n",
      "7   5.0   0.688462      0.46524    0.783552     0.216448  0.688910  0.466323   \n",
      "8  10.0   0.688462      0.46524    0.783552     0.216448  0.689846  0.466323   \n",
      "9  20.0   0.688462      0.46524    0.783552     0.216448  0.689339  0.467404   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.783552  0.216448  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "1  0.783552  0.216448  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "2  0.783552  0.216448  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "3  0.783047  0.216953  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "4  0.783047  0.216953  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "5  0.783047  0.216953  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "6  0.782543  0.217457  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "7  0.782543  0.217457  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "8  0.782543  0.217457  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "9  0.781534  0.218466  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0         0.46524       0.783552        0.216448  \n",
      "1         0.46524       0.783552        0.216448  \n",
      "2         0.46524       0.783552        0.216448  \n",
      "3         0.46524       0.783552        0.216448  \n",
      "4         0.46524       0.783552        0.216448  \n",
      "5         0.46524       0.783552        0.216448  \n",
      "6         0.46524       0.783552        0.216448  \n",
      "7         0.46524       0.783552        0.216448  \n",
      "8         0.46524       0.783552        0.216448  \n",
      "9         0.46524       0.783552        0.216448  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "1     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "2     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "3     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "1        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "2        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "3        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.216448  0.688462   0.465240  0.783552   0.216448  (10, 10, 10)  \n",
      "1   0.216448  0.688462   0.465240  0.783552   0.216448     (5, 5, 5)  \n",
      "2   0.216448  0.688462   0.465240  0.783552   0.216448     (3, 3, 3)  \n",
      "3   0.216448  0.687964   0.466323  0.782543   0.217457  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "1     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "2     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        0.46524      0.783552       0.216448  0.683095   0.478604  0.770938   \n",
      "1        0.46524      0.783552       0.216448  0.688462   0.465240  0.783552   \n",
      "2        0.46524      0.783552       0.216448  0.688462   0.465240  0.783552   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.229062  0.689102   0.471702  0.777497   0.222503  lbfgs  \n",
      "1   0.216448  0.688462   0.465240  0.783552   0.216448    sgd  \n",
      "2   0.216448  0.688462   0.465240  0.783552   0.216448   adam  \n",
      "df_NN\n",
      "5\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.270729   1.476182  0.268416   0.731584      0.271961   \n",
      "1    2  0.353517   1.325638  0.417760   0.582240      0.354317   \n",
      "2    3  0.343819   1.479084  0.381433   0.618567      0.344334   \n",
      "3    4  0.352157   1.435636  0.408678   0.591322      0.351670   \n",
      "4    5  0.373648   1.242739  0.437941   0.562059      0.373982   \n",
      "5    6  0.366043   1.164129  0.487386   0.512614      0.365647   \n",
      "6    7  0.373681   1.200404  0.458123   0.541877      0.374419   \n",
      "7    8  0.376161   1.211699  0.445510   0.554490      0.376775   \n",
      "8    9  0.372238   1.151711  0.483350   0.516650      0.373021   \n",
      "9   10  0.375581   1.158046  0.472250   0.527750      0.375512   \n",
      "10  11  0.373979   1.147102  0.480323   0.519677      0.373197   \n",
      "11  12  0.373453   1.138049  0.483855   0.516145      0.372646   \n",
      "12  13  0.373959   1.134052  0.486377   0.513623      0.373153   \n",
      "13  14  0.372002   1.133607  0.491423   0.508577      0.371139   \n",
      "14  15  0.365754   1.135608  0.500505   0.499495      0.365003   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0         1.475840       0.269425        0.730575    0.270729      1.476182   \n",
      "1         1.325257       0.418769        0.581231    0.353517      1.325638   \n",
      "2         1.478913       0.381937        0.618063    0.343819      1.479084   \n",
      "3         1.436163       0.408678        0.591322    0.352157      1.435636   \n",
      "4         1.242536       0.438446        0.561554    0.373648      1.242739   \n",
      "5         1.163912       0.487891        0.512109    0.366043      1.164129   \n",
      "6         1.200193       0.458628        0.541372    0.373681      1.200404   \n",
      "7         1.210866       0.446014        0.553986    0.376161      1.211699   \n",
      "8         1.150834       0.483855        0.516145    0.372238      1.151711   \n",
      "9         1.157392       0.472250        0.527750    0.375581      1.158046   \n",
      "10        1.147322       0.479818        0.520182    0.373979      1.147102   \n",
      "11        1.138271       0.483350        0.516650    0.373453      1.138049   \n",
      "12        1.134275       0.485873        0.514127    0.373959      1.134052   \n",
      "13        1.133830       0.490918        0.509082    0.372002      1.133607   \n",
      "14        1.135608       0.500505        0.499495    0.365754      1.135608   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.268416      0.731584  0.367311    1.318004   0.420283    0.579717  \n",
      "1      0.417760      0.582240  0.349111    1.306469   0.407669    0.592331  \n",
      "2      0.381433      0.618567  0.371919    1.230704   0.428860    0.571140  \n",
      "3      0.408678      0.591322  0.364961    1.213779   0.443996    0.556004  \n",
      "4      0.437941      0.562059  0.373796    1.142474   0.478305    0.521695  \n",
      "5      0.487386      0.512614  0.370351    1.134942   0.490414    0.509586  \n",
      "6      0.458123      0.541877  0.372562    1.142032   0.488900    0.511100  \n",
      "7      0.445510      0.554490  0.331391    1.167591   0.363269    0.636731  \n",
      "8      0.483350      0.516650  0.331221    1.168455   0.363774    0.636226  \n",
      "9      0.472250      0.527750  0.333310    1.165862   0.363774    0.636226  \n",
      "10     0.480323      0.519677  0.330006    1.169750   0.360242    0.639758  \n",
      "11     0.483855      0.516145  0.371613    1.132271   0.493946    0.506054  \n",
      "12     0.486377      0.513623  0.373158    1.127807   0.497477    0.502523  \n",
      "13     0.491423      0.508577  0.371645    1.128030   0.496973    0.503027  \n",
      "14     0.500505      0.499495  0.371363    1.128254   0.496468    0.503532  \n",
      "df_knn\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1       0.34801        1.109768       0.513118        0.486882   \n",
      "1    2       0.34801        1.109768       0.513118        0.486882   \n",
      "2    3       0.34801        1.109768       0.513118        0.486882   \n",
      "3    4       0.34801        1.109768       0.513118        0.486882   \n",
      "4    5       0.34801        1.109768       0.513118        0.486882   \n",
      "5    6       0.34801        1.109768       0.513118        0.486882   \n",
      "6    7       0.34801        1.109768       0.513118        0.486882   \n",
      "7    8       0.34801        1.109768       0.513118        0.486882   \n",
      "8    9       0.34801        1.109768       0.513118        0.486882   \n",
      "9   10       0.34801        1.109768       0.513118        0.486882   \n",
      "10  11       0.34801        1.109768       0.513118        0.486882   \n",
      "11  12       0.34801        1.109768       0.513118        0.486882   \n",
      "12  13       0.34801        1.109768       0.513118        0.486882   \n",
      "13  14       0.34801        1.109768       0.513118        0.486882   \n",
      "14  15       0.34801        1.109768       0.513118        0.486882   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm   sag_f1  \\\n",
      "0        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "1        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "2        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "3        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "4        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "5        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "6        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "7        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "8        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "9        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "10       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "11       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "12       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "13       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "14       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "\n",
      "    sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "1   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "2   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "3   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "4   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "5   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "6   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "7   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "8   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "9   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "10  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "11  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "12  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "13  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "14  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.348010      1.109768     0.513118      0.486882  0.348010   \n",
      "1           2    0.356954      1.105440     0.508073      0.491927  0.354255   \n",
      "2           3    0.352791      1.108630     0.511100      0.488900  0.352504   \n",
      "3           4    0.352169      1.108630     0.509586      0.490414  0.355488   \n",
      "4           5    0.355634      1.110904     0.506054      0.493946  0.360913   \n",
      "5           6    0.355972      1.114078     0.506054      0.493946  0.362977   \n",
      "6           7    0.355152      1.116114     0.502523      0.497477  0.360953   \n",
      "7           8    0.356184      1.124446     0.498991      0.501009  0.360522   \n",
      "8           9    0.358000      1.125343     0.497477      0.502523  0.359517   \n",
      "9          10    0.357850      1.128254     0.494450      0.505550  0.363880   \n",
      "10         11    0.355899      1.130488     0.496468      0.503532  0.364883   \n",
      "11         12    0.356509      1.128030     0.496468      0.503532  0.364957   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0    1.109768  0.513118   0.486882  \n",
      "1    1.106809  0.508577   0.491423  \n",
      "2    1.111585  0.506054   0.493946  \n",
      "3    1.111358  0.505550   0.494450  \n",
      "4    1.118147  0.506559   0.493441  \n",
      "5    1.121751  0.507568   0.492432  \n",
      "6    1.125792  0.505550   0.494450  \n",
      "7    1.127359  0.504541   0.495459  \n",
      "8    1.130041  0.502523   0.497477  \n",
      "9    1.129818  0.504541   0.495459  \n",
      "10   1.134719  0.501009   0.498991  \n",
      "11   1.136053  0.499495   0.500505  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.369901      1.123549     0.496468      0.503532   \n",
      "1            10    0.360309      1.118147     0.502523      0.497477   \n",
      "2            15    0.375029      1.115210     0.504036      0.495964   \n",
      "3            20    0.362194      1.132717     0.498991      0.501009   \n",
      "4            25    0.367071      1.129818     0.499495      0.500505   \n",
      "5            30    0.363992      1.124895     0.499495      0.500505   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.365704   1.122650  0.497477   0.502523  \n",
      "1  0.366394   1.126464  0.497982   0.502018  \n",
      "2  0.365310   1.129371  0.504541   0.495459  \n",
      "3  0.364664   1.126016  0.499495   0.500505  \n",
      "4  0.364677   1.121976  0.498991   0.501009  \n",
      "5  0.361713   1.124671  0.503027   0.496973  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.348675    1.109995   0.512614    0.487386    0.355248   \n",
      "1            10  0.348675    1.109995   0.512614    0.487386    0.355150   \n",
      "2            15  0.348675    1.109995   0.512614    0.487386    0.355150   \n",
      "3            20  0.348675    1.109995   0.512614    0.487386    0.355925   \n",
      "4            25  0.348675    1.109995   0.512614    0.487386    0.355560   \n",
      "5            30  0.348446    1.110222   0.512109    0.487891    0.352664   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0      1.107720     0.510595      0.489405  \n",
      "1      1.107036     0.510595      0.489405  \n",
      "2      1.107036     0.510595      0.489405  \n",
      "3      1.111131     0.506054      0.493946  \n",
      "4      1.110904     0.505045      0.494955  \n",
      "5      1.111131     0.505045      0.494955  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1  rbf_rmse  \\\n",
      "0   0.5    0.34801     1.109768    0.513118     0.486882  0.348010  1.109768   \n",
      "1   1.0    0.34801     1.109768    0.513118     0.486882  0.349018  1.108630   \n",
      "2   1.5    0.34801     1.109768    0.513118     0.486882  0.352170  1.109995   \n",
      "3   2.0    0.34801     1.109768    0.513118     0.486882  0.352304  1.112946   \n",
      "4   2.5    0.34801     1.109768    0.513118     0.486882  0.354703  1.114305   \n",
      "5   3.0    0.34801     1.109768    0.513118     0.486882  0.355583  1.117695   \n",
      "6   4.0    0.34801     1.109768    0.513118     0.486882  0.358604  1.117470   \n",
      "7   5.0    0.34801     1.109768    0.513118     0.486882  0.358584  1.117470   \n",
      "8  10.0    0.34801     1.109768    0.513118     0.486882  0.361171  1.122650   \n",
      "9  20.0    0.34801     1.109768    0.513118     0.486882  0.362120  1.126016   \n",
      "\n",
      "    rbf_acc  rbf_hamm  poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.513118  0.486882  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "1  0.513118  0.486882  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "2  0.511604  0.488396  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "3  0.506559  0.493441  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "4  0.507064  0.492936  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "5  0.506559  0.493441  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "6  0.505045  0.494955  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "7  0.505045  0.494955  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "8  0.504036  0.495964  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "9  0.502018  0.497982  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0        1.109768       0.513118        0.486882  \n",
      "1        1.109768       0.513118        0.486882  \n",
      "2        1.109768       0.513118        0.486882  \n",
      "3        1.109768       0.513118        0.486882  \n",
      "4        1.109768       0.513118        0.486882  \n",
      "5        1.109768       0.513118        0.486882  \n",
      "6        1.109768       0.513118        0.486882  \n",
      "7        1.109768       0.513118        0.486882  \n",
      "8        1.109768       0.513118        0.486882  \n",
      "9        1.109768       0.513118        0.486882  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "1      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "2      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "3      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "1       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "2       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "3       1.109768      0.513118       0.486882  0.347784   1.109995  0.512614   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.486882  0.348010   1.109768  0.513118   0.486882  (10, 10, 10)  \n",
      "1   0.486882  0.348010   1.109768  0.513118   0.486882     (5, 5, 5)  \n",
      "2   0.486882  0.348010   1.109768  0.513118   0.486882     (3, 3, 3)  \n",
      "3   0.487386  0.364483   1.119049  0.498991   0.501009  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "1      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "2      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0       1.109768      0.513118       0.486882  0.368512   1.130711  0.497982   \n",
      "1       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "2       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.502018  0.363289   1.117921  0.505550   0.494450  lbfgs  \n",
      "1   0.486882  0.348010   1.109768  0.513118   0.486882    sgd  \n",
      "2   0.486882  0.348904   1.111585  0.512109   0.487891   adam  \n",
      "df_NN\n",
      "10\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.133975   2.852053  0.145308   0.854692      0.133931   \n",
      "1    2  0.158259   2.717900  0.212412   0.787588      0.158617   \n",
      "2    3  0.166928   2.693098  0.219980   0.780020      0.166668   \n",
      "3    4  0.165441   2.667308  0.216448   0.783552      0.165214   \n",
      "4    5  0.173990   2.625459  0.224016   0.775984      0.173427   \n",
      "5    6  0.175421   2.511829  0.242180   0.757820      0.174444   \n",
      "6    7  0.177968   2.507909  0.242684   0.757316      0.177417   \n",
      "7    8  0.181016   2.498637  0.245711   0.754289      0.180979   \n",
      "8    9  0.189783   2.486898  0.250757   0.749243      0.189696   \n",
      "9   10  0.194263   2.455867  0.256307   0.743693      0.194254   \n",
      "10  11  0.184093   2.459357  0.257316   0.742684      0.183624   \n",
      "11  12  0.187078   2.387848  0.253280   0.746720      0.186910   \n",
      "12  13  0.197676   2.422773  0.258325   0.741675      0.197453   \n",
      "13  14  0.189198   2.480397  0.254793   0.745207      0.188608   \n",
      "14  15  0.182095   2.405636  0.260848   0.739152      0.182395   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0         2.851788       0.145308        0.854692    0.133975      2.852053   \n",
      "1         2.717808       0.212916        0.787084    0.158259      2.717900   \n",
      "2         2.692254       0.219980        0.780020    0.166928      2.693098   \n",
      "3         2.666929       0.216448        0.783552    0.165441      2.667308   \n",
      "4         2.627572       0.223512        0.776488    0.173990      2.625459   \n",
      "5         2.511929       0.241675        0.758325    0.175421      2.511829   \n",
      "6         2.508009       0.242180        0.757820    0.177968      2.507909   \n",
      "7         2.497426       0.246216        0.753784    0.181016      2.498637   \n",
      "8         2.483650       0.250757        0.749243    0.189783      2.486898   \n",
      "9         2.455661       0.256307        0.743693    0.194263      2.455867   \n",
      "10        2.460997       0.256811        0.743189    0.184093      2.459357   \n",
      "11        2.389432       0.253280        0.746720    0.187078      2.387848   \n",
      "12        2.424854       0.257820        0.742180    0.197676      2.422773   \n",
      "13        2.480906       0.254289        0.745711    0.189198      2.480397   \n",
      "14        2.405950       0.261352        0.738648    0.182095      2.405636   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.145308      0.854692  0.168026    2.667970   0.219980    0.780020  \n",
      "1      0.212412      0.787588  0.146789    2.675995   0.218466    0.781534  \n",
      "2      0.219980      0.780020  0.176000    2.546936   0.206357    0.793643  \n",
      "3      0.216448      0.783552  0.128744    3.204516   0.143794    0.856206  \n",
      "4      0.224016      0.775984  0.177925    2.490446   0.249748    0.750252  \n",
      "5      0.242180      0.757820  0.169475    2.627572   0.242180    0.757820  \n",
      "6      0.242684      0.757316  0.158363    2.515843   0.172553    0.827447  \n",
      "7      0.245711      0.754289  0.153579    2.525051   0.174571    0.825429  \n",
      "8      0.250757      0.749243  0.158492    2.515041   0.178103    0.821897  \n",
      "9      0.256307      0.743693  0.162269    2.524252   0.174067    0.825933  \n",
      "10     0.257316      0.742684  0.161433    2.539298   0.175580    0.824420  \n",
      "11     0.253280      0.746720  0.160933    2.512331   0.181130    0.818870  \n",
      "12     0.258325      0.741675  0.182975    2.408884   0.261857    0.738143  \n",
      "13     0.254793      0.745207  0.184031    2.413593   0.261352    0.738648  \n",
      "14     0.260848      0.739152  0.178508    2.432437   0.260848    0.739152  \n",
      "df_knn\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1       0.14676         2.43741       0.281029        0.718971   \n",
      "1    2       0.14676         2.43741       0.281029        0.718971   \n",
      "2    3       0.14676         2.43741       0.281029        0.718971   \n",
      "3    4       0.14676         2.43741       0.281029        0.718971   \n",
      "4    5       0.14676         2.43741       0.281029        0.718971   \n",
      "5    6       0.14676         2.43741       0.281029        0.718971   \n",
      "6    7       0.14676         2.43741       0.281029        0.718971   \n",
      "7    8       0.14676         2.43741       0.281029        0.718971   \n",
      "8    9       0.14676         2.43741       0.281029        0.718971   \n",
      "9   10       0.14676         2.43741       0.281029        0.718971   \n",
      "10  11       0.14676         2.43741       0.281029        0.718971   \n",
      "11  12       0.14676         2.43741       0.281029        0.718971   \n",
      "12  13       0.14676         2.43741       0.281029        0.718971   \n",
      "13  14       0.14676         2.43741       0.281029        0.718971   \n",
      "14  15       0.14676         2.43741       0.281029        0.718971   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "1       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "2       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "3       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "4       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "5       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "6       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "7       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "8       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "9       0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "10      0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "11      0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "12      0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "13      0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "14      0.146762        2.437928       0.281029        0.718971  0.146762   \n",
      "\n",
      "    sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "1   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "2   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "3   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "4   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "5   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "6   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "7   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "8   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "9   2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "10  2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "11  2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "12  2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "13  2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "14  2.437928  0.281029  0.718971  0.146762    2.437928   0.281029    0.718971  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.142292      2.435650     0.274975      0.725025  0.143013   \n",
      "1           2    0.142292      2.435650     0.274975      0.725025  0.133456   \n",
      "2           3    0.133994      2.443509     0.273461      0.726539  0.134820   \n",
      "3           4    0.137612      2.447017     0.274975      0.725025  0.155022   \n",
      "4           5    0.137319      2.438135     0.270434      0.729566  0.154592   \n",
      "5           6    0.144209      2.437928     0.273966      0.726034  0.148841   \n",
      "6           7    0.146921      2.431400     0.273966      0.726034  0.172948   \n",
      "7           8    0.154560      2.424438     0.274470      0.725530  0.172448   \n",
      "8           9    0.161649      2.425583     0.276993      0.723007  0.173696   \n",
      "9          10    0.160769      2.423918     0.274975      0.725025  0.173811   \n",
      "10         11    0.165335      2.432126     0.276488      0.723512  0.177356   \n",
      "11         12    0.164449      2.438238     0.275479      0.724521  0.176625   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0    2.437410  0.278002   0.721998  \n",
      "1    2.433785  0.271443   0.728557  \n",
      "2    2.436686  0.270434   0.729566  \n",
      "3    2.416204  0.269425   0.730575  \n",
      "4    2.418813  0.272452   0.727548  \n",
      "5    2.431089  0.273966   0.726034  \n",
      "6    2.409513  0.273461   0.726539  \n",
      "7    2.415578  0.273461   0.726539  \n",
      "8    2.429220  0.272452   0.727548  \n",
      "9    2.434407  0.272452   0.727548  \n",
      "10   2.429324  0.272452   0.727548  \n",
      "11   2.425895  0.271948   0.728052  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.176602      2.430466     0.269929      0.730071   \n",
      "1            10    0.180868      2.415891     0.267407      0.732593   \n",
      "2            15    0.180158      2.431400     0.273966      0.726034   \n",
      "3            20    0.179173      2.395653     0.266902      0.733098   \n",
      "4            25    0.187754      2.392070     0.277497      0.722503   \n",
      "5            30    0.181784      2.393440     0.267407      0.732593   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.183833   2.437410  0.273461   0.726539  \n",
      "1  0.183563   2.407837  0.272452   0.727548  \n",
      "2  0.187454   2.409617  0.275479   0.724521  \n",
      "3  0.187076   2.400071  0.271948   0.728052  \n",
      "4  0.186985   2.407208  0.274975   0.725025  \n",
      "5  0.179995   2.403852  0.272452   0.727548  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.107667    2.134007   0.236125    0.763875    0.146292   \n",
      "1            10  0.117744    2.459767   0.271948    0.728052    0.133205   \n",
      "2            15  0.117744    2.459767   0.271948    0.728052    0.143784   \n",
      "3            20  0.117744    2.459767   0.271948    0.728052    0.141610   \n",
      "4            25  0.121770    2.458639   0.270938    0.729062    0.142066   \n",
      "5            30  0.124447    2.457612   0.271443    0.728557    0.138368   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0      2.437514     0.280020      0.719980  \n",
      "1      2.439686     0.268416      0.731584  \n",
      "2      2.598901     0.265893      0.734107  \n",
      "3      2.622479     0.263875      0.736125  \n",
      "4      2.594724     0.262866      0.737134  \n",
      "5      2.581175     0.260343      0.739657  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1  rbf_rmse  \\\n",
      "0   0.5   0.115517      2.46069    0.270938     0.729062  0.163323  2.412338   \n",
      "1   1.0   0.115517      2.46069    0.270938     0.729062  0.163907  2.414324   \n",
      "2   1.5   0.115517      2.46069    0.270938     0.729062  0.167288  2.419334   \n",
      "3   2.0   0.115517      2.46069    0.270938     0.729062  0.168446  2.413279   \n",
      "4   2.5   0.115517      2.46069    0.270938     0.729062  0.171184  2.412756   \n",
      "5   3.0   0.115517      2.46069    0.270938     0.729062  0.173778  2.411710   \n",
      "6   4.0   0.115517      2.46069    0.270938     0.729062  0.173391  2.407942   \n",
      "7   5.0   0.115517      2.46069    0.270938     0.729062  0.173444  2.412756   \n",
      "8  10.0   0.115517      2.46069    0.270938     0.729062  0.174449  2.415786   \n",
      "9  20.0   0.115517      2.46069    0.270938     0.729062  0.180204  2.412756   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.279516  0.720484  0.146188   2.428493  0.275984   0.724016      0.147357   \n",
      "1  0.272957  0.727043  0.161740   2.408151  0.274470   0.725530      0.147357   \n",
      "2  0.272957  0.727043  0.161996   2.408047  0.274975   0.725025      0.147357   \n",
      "3  0.272957  0.727043  0.161996   2.408047  0.274975   0.725025      0.147357   \n",
      "4  0.273966  0.726034  0.161368   2.408151  0.274470   0.725530      0.147357   \n",
      "5  0.274470  0.725530  0.161623   2.408047  0.274975   0.725025      0.147357   \n",
      "6  0.273461  0.726539  0.161637   2.407732  0.274975   0.725025      0.147357   \n",
      "7  0.273461  0.726539  0.162821   2.404062  0.275984   0.724016      0.147357   \n",
      "8  0.273461  0.726539  0.162821   2.404062  0.275984   0.724016      0.147357   \n",
      "9  0.275479  0.724521  0.162821   2.404062  0.275984   0.724016      0.147357   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0         2.43741       0.281029        0.718971  \n",
      "1         2.43741       0.281029        0.718971  \n",
      "2         2.43741       0.281029        0.718971  \n",
      "3         2.43741       0.281029        0.718971  \n",
      "4         2.43741       0.281029        0.718971  \n",
      "5         2.43741       0.281029        0.718971  \n",
      "6         2.43741       0.281029        0.718971  \n",
      "7         2.43741       0.281029        0.718971  \n",
      "8         2.43741       0.281029        0.718971  \n",
      "9         2.43741       0.281029        0.718971  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.131180       2.451137      0.274470       0.725530     0.115517   \n",
      "1     0.115348       2.460792      0.270434       0.729566     0.115517   \n",
      "2     0.115517       2.460690      0.270938       0.729062     0.115517   \n",
      "3     0.167187       2.410246      0.279516       0.720484     0.115517   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        2.46069      0.270938       0.729062  0.158462   2.424646  0.282543   \n",
      "1        2.46069      0.270938       0.729062  0.125276   2.456996  0.270938   \n",
      "2        2.46069      0.270938       0.729062  0.115517   2.460690  0.270938   \n",
      "3        2.46069      0.270938       0.729062  0.127835   2.451857  0.273461   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.717457  0.145615   2.424646  0.277497   0.722503  (10, 10, 10)  \n",
      "1   0.729062  0.115517   2.460690  0.270938   0.729062     (5, 5, 5)  \n",
      "2   0.729062  0.115517   2.460690  0.270938   0.729062     (3, 3, 3)  \n",
      "3   0.726539  0.173163   2.415160  0.273461   0.726539  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.147220       2.437410      0.282038       0.717962     0.115517   \n",
      "1     0.163001       2.421002      0.276488       0.723512     0.115517   \n",
      "2     0.138433       2.445470      0.278002       0.721998     0.115517   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        2.46069      0.270938       0.729062  0.176324   2.426726  0.270938   \n",
      "1        2.46069      0.270938       0.729062  0.121283   2.460177  0.271948   \n",
      "2        2.46069      0.270938       0.729062  0.129934   2.454839  0.273461   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.729062  0.162256   2.440513  0.275479   0.724521  lbfgs  \n",
      "1   0.728052  0.115517   2.460690  0.270938   0.729062    sgd  \n",
      "2   0.726539  0.141374   2.435754  0.278507   0.721493   adam  \n",
      "df_NN\n",
      "100\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.006895  28.706191  0.013623   0.986377      0.006880   \n",
      "1    2  0.012578  27.386598  0.028759   0.971241      0.012558   \n",
      "2    3  0.012285  27.933990  0.028254   0.971746      0.012279   \n",
      "3    4  0.011283  27.939146  0.028254   0.971746      0.011282   \n",
      "4    5  0.010515  28.176734  0.027750   0.972250      0.011333   \n",
      "5    6  0.007748  28.549787  0.024723   0.975277      0.007741   \n",
      "6    7  0.008915  28.537917  0.024723   0.975277      0.008907   \n",
      "7    8  0.008918  32.961502  0.024218   0.975782      0.009736   \n",
      "8    9  0.011213  28.537157  0.026741   0.973259      0.012048   \n",
      "9   10  0.008237  28.370335  0.023209   0.976791      0.009078   \n",
      "10  11  0.008111  28.118084  0.023209   0.976791      0.008935   \n",
      "11  12  0.008843  27.644255  0.023713   0.976287      0.008850   \n",
      "12  13  0.008507  28.826957  0.013118   0.986882      0.008506   \n",
      "13  14  0.009647  27.812031  0.014632   0.985368      0.009659   \n",
      "14  15  0.011917  26.748869  0.027245   0.972755      0.011931   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0        28.705646       0.013623        0.986377    0.006895     28.706191   \n",
      "1        27.384562       0.028759        0.971241    0.012578     27.386598   \n",
      "2        27.931994       0.028254        0.971746    0.012285     27.933990   \n",
      "3        27.940654       0.028254        0.971746    0.011283     27.939146   \n",
      "4        28.171819       0.028254        0.971746    0.010515     28.176734   \n",
      "5        28.547516       0.024723        0.975277    0.007748     28.549787   \n",
      "6        28.535645       0.024723        0.975277    0.008915     28.537917   \n",
      "7        32.958273       0.024723        0.975277    0.008918     32.961502   \n",
      "8        28.528032       0.027245        0.972755    0.011213     28.537157   \n",
      "9        28.358817       0.023713        0.976287    0.008237     28.370335   \n",
      "10       28.127700       0.023713        0.976287    0.008111     28.118084   \n",
      "11       27.651746       0.023713        0.976287    0.008843     27.644255   \n",
      "12       28.833747       0.013118        0.986882    0.008507     28.826957   \n",
      "13       27.823014       0.014632        0.985368    0.009647     27.812031   \n",
      "14       26.771033       0.027245        0.972755    0.011917     26.748869   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.013623      0.986377  0.016388   27.350843   0.029263    0.970737  \n",
      "1      0.028759      0.971241  0.013919   27.355427   0.028759    0.971241  \n",
      "2      0.028254      0.971746  0.010978   27.562854   0.027750    0.972250  \n",
      "3      0.028254      0.971746  0.011198   33.917229   0.018163    0.981837  \n",
      "4      0.027750      0.972250  0.011116   33.811529   0.019173    0.980827  \n",
      "5      0.024723      0.975277  0.012008   28.509819   0.019677    0.980323  \n",
      "6      0.024723      0.975277  0.012676   28.483208   0.020182    0.979818  \n",
      "7      0.024218      0.975782  0.011590   28.800647   0.016650    0.983350  \n",
      "8      0.026741      0.973259  0.011661   27.236195   0.016650    0.983350  \n",
      "9      0.023209      0.976791  0.010556   27.241631   0.015641    0.984359  \n",
      "10     0.023209      0.976791  0.009817   26.142057   0.015641    0.984359  \n",
      "11     0.023713      0.976287  0.009505   26.852298   0.014632    0.985368  \n",
      "12     0.013118      0.986882  0.009406   26.314379   0.014127    0.985873  \n",
      "13     0.014632      0.985368  0.010379   26.058713   0.015641    0.984359  \n",
      "14     0.027245      0.972755  0.011814   24.232112   0.022200    0.977800  \n",
      "df_knn\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1      0.011024       22.928936       0.028759        0.971241   \n",
      "1    2      0.010579       22.989698       0.029263        0.970737   \n",
      "2    3      0.010585       22.993681       0.029263        0.970737   \n",
      "3    4      0.009814       22.992979       0.028759        0.971241   \n",
      "4    5      0.009819       22.992628       0.028759        0.971241   \n",
      "5    6      0.009819       22.992628       0.028759        0.971241   \n",
      "6    7      0.009819       22.992628       0.028759        0.971241   \n",
      "7    8      0.009819       23.021017       0.028759        0.971241   \n",
      "8    9      0.009819       23.021017       0.028759        0.971241   \n",
      "9   10      0.009819       23.081733       0.028759        0.971241   \n",
      "10  11      0.009819       23.067652       0.028759        0.971241   \n",
      "11  12      0.009819       23.067652       0.028759        0.971241   \n",
      "12  13      0.009819       23.067652       0.028759        0.971241   \n",
      "13  14      0.009819       23.067652       0.028759        0.971241   \n",
      "14  15      0.009819       23.067652       0.028759        0.971241   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.011042       22.931907       0.028759        0.971241  0.011042   \n",
      "1       0.010585       22.993681       0.029263        0.970737  0.010585   \n",
      "2       0.009819       22.992628       0.028759        0.971241  0.009819   \n",
      "3       0.009819       23.004299       0.028759        0.971241  0.009819   \n",
      "4       0.009819       23.024567       0.028759        0.971241  0.009819   \n",
      "5       0.009819       23.083307       0.028759        0.971241  0.009819   \n",
      "6       0.009819       23.083307       0.028759        0.971241  0.009819   \n",
      "7       0.009819       23.069226       0.028759        0.971241  0.009819   \n",
      "8       0.009819       23.069226       0.028759        0.971241  0.009819   \n",
      "9       0.009819       23.069226       0.028759        0.971241  0.009819   \n",
      "10      0.009819       23.069226       0.028759        0.971241  0.009819   \n",
      "11      0.009819       23.069226       0.028759        0.971241  0.009819   \n",
      "12      0.009819       23.069226       0.028759        0.971241  0.009819   \n",
      "13      0.009819       23.069226       0.028759        0.971241  0.009819   \n",
      "14      0.009819       23.069226       0.028759        0.971241  0.009819   \n",
      "\n",
      "     sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0   22.931907  0.028759  0.971241  0.011042   22.931907   0.028759    0.971241  \n",
      "1   22.993681  0.029263  0.970737  0.010585   22.993681   0.029263    0.970737  \n",
      "2   22.992628  0.028759  0.971241  0.009819   22.992628   0.028759    0.971241  \n",
      "3   23.004299  0.028759  0.971241  0.009819   23.004299   0.028759    0.971241  \n",
      "4   23.024567  0.028759  0.971241  0.009819   23.024567   0.028759    0.971241  \n",
      "5   23.083307  0.028759  0.971241  0.009819   23.083307   0.028759    0.971241  \n",
      "6   23.083307  0.028759  0.971241  0.009819   23.083307   0.028759    0.971241  \n",
      "7   23.069226  0.028759  0.971241  0.009819   23.069226   0.028759    0.971241  \n",
      "8   23.069226  0.028759  0.971241  0.009819   23.069226   0.028759    0.971241  \n",
      "9   23.069226  0.028759  0.971241  0.009819   23.069226   0.028759    0.971241  \n",
      "10  23.069226  0.028759  0.971241  0.009819   23.069226   0.028759    0.971241  \n",
      "11  23.069226  0.028759  0.971241  0.009819   23.069226   0.028759    0.971241  \n",
      "12  23.069226  0.028759  0.971241  0.009819   23.069226   0.028759    0.971241  \n",
      "13  23.069226  0.028759  0.971241  0.009819   23.069226   0.028759    0.971241  \n",
      "14  23.069226  0.028759  0.971241  0.009819   23.069226   0.028759    0.971241  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.002654     22.325961     0.026741      0.973259  0.002654   \n",
      "1           2    0.003620     22.266198     0.026236      0.973764  0.001755   \n",
      "2           3    0.007448     23.591846     0.027245      0.972755  0.003077   \n",
      "3           4    0.010882     23.307924     0.028759      0.971241  0.003922   \n",
      "4           5    0.011674     23.213548     0.027750      0.972250  0.005723   \n",
      "5           6    0.015577     23.616534     0.030777      0.969223  0.006776   \n",
      "6           7    0.012983     24.837514     0.027750      0.972250  0.006672   \n",
      "7           8    0.014085     24.259892     0.027750      0.972250  0.008479   \n",
      "8           9    0.014782     24.049625     0.027750      0.972250  0.007988   \n",
      "9          10    0.014436     23.970235     0.027245      0.972755  0.010017   \n",
      "10         11    0.014903     23.938989     0.027750      0.972250  0.010342   \n",
      "11         12    0.015134     23.979347     0.027750      0.972250  0.011498   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0   22.325961  0.026741   0.973259  \n",
      "1   22.402035  0.025732   0.974268  \n",
      "2   22.511383  0.026741   0.973259  \n",
      "3   22.656653  0.026741   0.973259  \n",
      "4   22.742770  0.027245   0.972755  \n",
      "5   23.029256  0.024723   0.975277  \n",
      "6   23.214363  0.024218   0.975782  \n",
      "7   23.676533  0.030777   0.969223  \n",
      "8   23.543163  0.024218   0.975782  \n",
      "9   24.092426  0.028759   0.971241  \n",
      "10  24.011097  0.026236   0.973764  \n",
      "11  25.541699  0.027245   0.972755  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.011332     24.753558     0.020182      0.979818   \n",
      "1            10    0.016907     26.457189     0.030272      0.969728   \n",
      "2            15    0.014816     23.448916     0.028759      0.971241   \n",
      "3            20    0.014912     25.070737     0.027245      0.972755   \n",
      "4            25    0.013575     23.494820     0.027245      0.972755   \n",
      "5            30    0.012285     23.398783     0.025227      0.974773   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.012685  25.624471  0.024723   0.975277  \n",
      "1  0.009890  23.699068  0.024218   0.975782  \n",
      "2  0.015266  24.468198  0.029263   0.970737  \n",
      "3  0.010554  24.068750  0.024218   0.975782  \n",
      "4  0.014104  23.800731  0.027245   0.972755  \n",
      "5  0.013463  23.239604  0.026741   0.973259  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.002327   23.623401   0.026741    0.973259    0.007296   \n",
      "1            10  0.001779   64.877300   0.030272    0.969728    0.006363   \n",
      "2            15  0.001779   64.877300   0.030272    0.969728    0.005972   \n",
      "3            20  0.001779   64.877300   0.030272    0.969728    0.008320   \n",
      "4            25  0.001775   64.377125   0.029768    0.970232    0.006957   \n",
      "5            30  0.001775   64.377125   0.029768    0.970232    0.008125   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0     22.563678     0.031786      0.968214  \n",
      "1     24.297122     0.023209      0.976791  \n",
      "2     23.861260     0.026741      0.973259  \n",
      "3     23.321352     0.027245      0.972755  \n",
      "4     27.809872     0.023209      0.976791  \n",
      "5     26.665747     0.025732      0.974268  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1   rbf_rmse  \\\n",
      "0   0.5   0.005902    22.978953    0.025732     0.974268  0.005621  23.100677   \n",
      "1   1.0   0.005551    23.022584    0.024723     0.975277  0.008573  23.125442   \n",
      "2   1.5   0.007662    23.019252    0.026236     0.973764  0.011254  23.210516   \n",
      "3   2.0   0.007678    23.013805    0.026236     0.973764  0.014116  24.178782   \n",
      "4   2.5   0.008646    23.046612    0.026741     0.973259  0.014395  24.092112   \n",
      "5   3.0   0.008560    23.025443    0.026741     0.973259  0.014061  23.189443   \n",
      "6   4.0   0.008592    23.021258    0.026741     0.973259  0.012740  24.105909   \n",
      "7   5.0   0.008606    23.020359    0.026741     0.973259  0.012455  24.194104   \n",
      "8  10.0   0.008315    23.148666    0.025227     0.974773  0.013505  24.032258   \n",
      "9  20.0   0.008314    23.146399    0.025227     0.974773  0.015006  24.035859   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.025732  0.974268  0.013000  23.202167  0.029263   0.970737       0.01102   \n",
      "1  0.026236  0.973764  0.015801  23.296644  0.031282   0.968718       0.01102   \n",
      "2  0.027750  0.972250  0.016256  23.217645  0.031786   0.968214       0.01102   \n",
      "3  0.028254  0.971746  0.016561  23.331356  0.030777   0.969223       0.01102   \n",
      "4  0.029263  0.970737  0.016593  23.182610  0.030777   0.969223       0.01102   \n",
      "5  0.028759  0.971241  0.016514  23.160444  0.030777   0.969223       0.01102   \n",
      "6  0.027750  0.972250  0.015248  23.128791  0.030272   0.969728       0.01102   \n",
      "7  0.027245  0.972755  0.014401  23.149255  0.029768   0.970232       0.01102   \n",
      "8  0.028254  0.971746  0.012743  23.313389  0.027750   0.972250       0.01102   \n",
      "9  0.029768  0.970232  0.013469  23.302187  0.028759   0.971241       0.01102   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0       22.931159       0.029768        0.970232  \n",
      "1       22.931159       0.029768        0.970232  \n",
      "2       22.931159       0.029768        0.970232  \n",
      "3       22.931159       0.029768        0.970232  \n",
      "4       22.931159       0.029768        0.970232  \n",
      "5       22.931159       0.029768        0.970232  \n",
      "6       22.931159       0.029768        0.970232  \n",
      "7       22.931159       0.029768        0.970232  \n",
      "8       22.931159       0.029768        0.970232  \n",
      "9       22.931159       0.029768        0.970232  \n",
      "df_SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.010703      23.197448      0.029768       0.970232     0.001499   \n",
      "1     0.009062      22.730932      0.032795       0.967205     0.001499   \n",
      "2     0.007768      23.125868      0.031282       0.968718     0.001499   \n",
      "3     0.010010      23.336189      0.027750       0.972250     0.001499   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0      22.486065       0.02775        0.97225  0.015107  23.885786  0.033300   \n",
      "1      22.486065       0.02775        0.97225  0.008215  23.110329  0.028254   \n",
      "2      22.486065       0.02775        0.97225  0.001484  22.485021  0.027245   \n",
      "3      22.486065       0.02775        0.97225  0.015420  23.837365  0.029768   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.966700  0.013179  24.303922  0.026741   0.973259  (10, 10, 10)  \n",
      "1   0.971746  0.004566  26.338756  0.027750   0.972250     (5, 5, 5)  \n",
      "2   0.972755  0.001499  22.486065  0.027750   0.972250     (3, 3, 3)  \n",
      "3   0.970232  0.009978  23.211951  0.026236   0.973764  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.010893      23.282107      0.029263       0.970737     0.001499   \n",
      "1     0.006128      22.725970      0.030777       0.969223     0.001499   \n",
      "2     0.011045      23.493832      0.028759       0.971241     0.001499   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0      22.486065       0.02775        0.97225  0.016292  27.202292  0.031786   \n",
      "1      22.486065       0.02775        0.97225  0.002781  22.508279  0.027750   \n",
      "2      22.486065       0.02775        0.97225  0.010065  22.935196  0.027750   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.968214  0.014501  24.048954  0.033300   0.966700  lbfgs  \n",
      "1   0.972250  0.004179  22.775082  0.024218   0.975782    sgd  \n",
      "2   0.972250  0.012277  23.253224  0.030272   0.969728   adam  \n",
      "df_NN\n"
     ]
    }
   ],
   "source": [
    "scale_list = [2, 5, 10, 100]\n",
    "file_name = \"model_summary_w_pca_7_final.xlsx\"\n",
    "for scale in scale_list:\n",
    "    print(scale)\n",
    "    Y_train, Y_dev = assign_y(scale)\n",
    "    df_knn = knn_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_NB = NB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_MNB = MNB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_GNB = GNB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_logR = LogR_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_DT = DT_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_RF = RF_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_AdaB = AdaB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_SVM = SVM_models(train_data1, Y_train, dev_data1)\n",
    "    df_NN1 = NN_models(train_data1, Y_train, dev_data1, Y_dev, \"L\")\n",
    "    df_NN2 = NN_models(train_data1, Y_train, dev_data1, Y_dev, \"S\")\n",
    "\n",
    "    wrt_excel(file_name, \"knn-\"+str(scale), df_knn)\n",
    "#     wrt_excel(file_name, \"NB-\"+str(scale), df_NB)    \n",
    "#     wrt_excel(file_name, \"MNB-\"+str(scale), df_MNB)\n",
    "#     wrt_excel(file_name, \"GNB-\"+str(scale), df_GNB)\n",
    "    wrt_excel(file_name, \"logR-\"+str(scale), df_logR)\n",
    "    wrt_excel(file_name, \"DT-\"+str(scale), df_DT)\n",
    "    wrt_excel(file_name, \"RF-\"+str(scale), df_RF)\n",
    "    wrt_excel(file_name, \"AdaB-\"+str(scale), df_AdaB)\n",
    "    wrt_excel(file_name, \"SVM-\"+str(scale), df_SVM)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"L\", df_NN1)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"S\", df_NN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 8 components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_pca = 8\n",
    "random_state = 0\n",
    "\n",
    "pca = PCA(n_components=components_pca, random_state=random_state)\n",
    "pca.fit(train_data)\n",
    "\n",
    "# overwriting train_data and dev_data to be the pca object - should do this in a cleaner way to preserve it but giving this a shot\n",
    "train_data2 = pca.transform(train_data)\n",
    "dev_data2 = pca.transform(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.690061   0.501763  0.748234   0.251766      0.690061   \n",
      "1    2  0.688064   0.473836  0.775479   0.224521      0.688064   \n",
      "2    3  0.689092   0.483324  0.766398   0.233602      0.689092   \n",
      "3    4  0.688323   0.473303  0.775984   0.224016      0.688323   \n",
      "4    5  0.690468   0.480708  0.768920   0.231080      0.690468   \n",
      "5    6  0.688583   0.472770  0.776488   0.223512      0.688583   \n",
      "6    7  0.689283   0.474900  0.774470   0.225530      0.689283   \n",
      "7    8  0.686968   0.468482  0.780525   0.219475      0.686968   \n",
      "8    9  0.686968   0.468482  0.780525   0.219475      0.686968   \n",
      "9   10  0.686968   0.468482  0.780525   0.219475      0.686968   \n",
      "10  11  0.686895   0.470631  0.778507   0.221493      0.686895   \n",
      "11  12  0.686895   0.470631  0.778507   0.221493      0.686895   \n",
      "12  13  0.686895   0.470631  0.778507   0.221493      0.686895   \n",
      "13  14  0.686968   0.468482  0.780525   0.219475      0.686968   \n",
      "14  15  0.686968   0.468482  0.780525   0.219475      0.686968   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0         0.501763       0.748234        0.251766    0.690061      0.501763   \n",
      "1         0.473836       0.775479        0.224521    0.688064      0.473836   \n",
      "2         0.483324       0.766398        0.233602    0.689092      0.483324   \n",
      "3         0.473303       0.775984        0.224016    0.688323      0.473303   \n",
      "4         0.480708       0.768920        0.231080    0.690468      0.480708   \n",
      "5         0.472770       0.776488        0.223512    0.688583      0.472770   \n",
      "6         0.474900       0.774470        0.225530    0.689283      0.474900   \n",
      "7         0.468482       0.780525        0.219475    0.686968      0.468482   \n",
      "8         0.468482       0.780525        0.219475    0.686968      0.468482   \n",
      "9         0.468482       0.780525        0.219475    0.686968      0.468482   \n",
      "10        0.470631       0.778507        0.221493    0.686895      0.470631   \n",
      "11        0.470631       0.778507        0.221493    0.686895      0.470631   \n",
      "12        0.470631       0.778507        0.221493    0.686895      0.470631   \n",
      "13        0.468482       0.780525        0.219475    0.686968      0.468482   \n",
      "14        0.468482       0.780525        0.219475    0.686968      0.468482   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.748234      0.251766  0.692171    0.498231   0.751766    0.248234  \n",
      "1      0.775479      0.224521  0.690193    0.481232   0.768416    0.231584  \n",
      "2      0.766398      0.233602  0.691639    0.484367   0.765388    0.234612  \n",
      "3      0.775984      0.224016  0.686968    0.468482   0.780525    0.219475  \n",
      "4      0.768920      0.231080  0.686895    0.470631   0.778507    0.221493  \n",
      "5      0.776488      0.223512  0.686895    0.470631   0.778507    0.221493  \n",
      "6      0.774470      0.225530  0.686895    0.470631   0.778507    0.221493  \n",
      "7      0.780525      0.219475  0.686968    0.468482   0.780525    0.219475  \n",
      "8      0.780525      0.219475  0.686895    0.470631   0.778507    0.221493  \n",
      "9      0.780525      0.219475  0.686895    0.470631   0.778507    0.221493  \n",
      "10     0.778507      0.221493  0.686895    0.470631   0.778507    0.221493  \n",
      "11     0.778507      0.221493  0.686968    0.468482   0.780525    0.219475  \n",
      "12     0.778507      0.221493  0.686968    0.468482   0.780525    0.219475  \n",
      "13     0.780525      0.219475  0.686968    0.468482   0.780525    0.219475  \n",
      "14     0.780525      0.219475  0.686968    0.468482   0.780525    0.219475  \n",
      "df_knn\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1      0.688462         0.46524       0.783552        0.216448   \n",
      "1    2      0.688462         0.46524       0.783552        0.216448   \n",
      "2    3      0.688462         0.46524       0.783552        0.216448   \n",
      "3    4      0.688462         0.46524       0.783552        0.216448   \n",
      "4    5      0.688462         0.46524       0.783552        0.216448   \n",
      "5    6      0.688462         0.46524       0.783552        0.216448   \n",
      "6    7      0.688462         0.46524       0.783552        0.216448   \n",
      "7    8      0.688462         0.46524       0.783552        0.216448   \n",
      "8    9      0.688462         0.46524       0.783552        0.216448   \n",
      "9   10      0.688462         0.46524       0.783552        0.216448   \n",
      "10  11      0.688462         0.46524       0.783552        0.216448   \n",
      "11  12      0.688462         0.46524       0.783552        0.216448   \n",
      "12  13      0.688462         0.46524       0.783552        0.216448   \n",
      "13  14      0.688462         0.46524       0.783552        0.216448   \n",
      "14  15      0.688462         0.46524       0.783552        0.216448   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "1       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "2       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "3       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "4       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "5       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "6       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "7       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "8       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "9       0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "10      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "11      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "12      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "13      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "14      0.688462         0.46524       0.783552        0.216448  0.688462   \n",
      "\n",
      "    sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "1    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "2    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "3    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "4    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "5    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "6    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "7    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "8    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "9    0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "10   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "11   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "12   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "13   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "14   0.46524  0.783552  0.216448  0.688462     0.46524   0.783552    0.216448  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.688462      0.465240     0.783552      0.216448  0.688462   \n",
      "1           2    0.688462      0.465240     0.783552      0.216448  0.688462   \n",
      "2           3    0.688462      0.465240     0.783552      0.216448  0.688462   \n",
      "3           4    0.688462      0.465240     0.783552      0.216448  0.688213   \n",
      "4           5    0.688462      0.465240     0.783552      0.216448  0.688213   \n",
      "5           6    0.688462      0.465240     0.783552      0.216448  0.688213   \n",
      "6           7    0.692601      0.466323     0.782543      0.217457  0.688213   \n",
      "7           8    0.689412      0.465240     0.783552      0.216448  0.688213   \n",
      "8           9    0.689412      0.465240     0.783552      0.216448  0.687964   \n",
      "9          10    0.690607      0.464697     0.784057      0.215943  0.687964   \n",
      "10         11    0.690607      0.464697     0.784057      0.215943  0.687964   \n",
      "11         12    0.689161      0.465782     0.783047      0.216953  0.688659   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0    0.465240  0.783552   0.216448  \n",
      "1    0.465240  0.783552   0.216448  \n",
      "2    0.465240  0.783552   0.216448  \n",
      "3    0.465782  0.783047   0.216953  \n",
      "4    0.465782  0.783047   0.216953  \n",
      "5    0.465782  0.783047   0.216953  \n",
      "6    0.465782  0.783047   0.216953  \n",
      "7    0.465782  0.783047   0.216953  \n",
      "8    0.466323  0.782543   0.217457  \n",
      "9    0.466323  0.782543   0.217457  \n",
      "10   0.466323  0.782543   0.217457  \n",
      "11   0.466864  0.782038   0.217962  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.690251      0.471167     0.778002      0.221998   \n",
      "1            10    0.690005      0.467943     0.781029      0.218971   \n",
      "2            15    0.686895      0.470631     0.778507      0.221493   \n",
      "3            20    0.688978      0.470095     0.779011      0.220989   \n",
      "4            25    0.689339      0.467404     0.781534      0.218466   \n",
      "5            30    0.689621      0.470631     0.778507      0.221493   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.689339   0.467404  0.781534   0.218466  \n",
      "1  0.686469   0.469558  0.779516   0.220484  \n",
      "2  0.689748   0.468482  0.780525   0.219475  \n",
      "3  0.688322   0.469558  0.779516   0.220484  \n",
      "4  0.688156   0.467943  0.781029   0.218971  \n",
      "5  0.688659   0.466864  0.782038   0.217962  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "1            10  0.688462     0.46524   0.783552    0.216448    0.688462   \n",
      "2            15  0.688462     0.46524   0.783552    0.216448    0.687466   \n",
      "3            20  0.688462     0.46524   0.783552    0.216448    0.688407   \n",
      "4            25  0.688462     0.46524   0.783552    0.216448    0.688407   \n",
      "5            30  0.688462     0.46524   0.783552    0.216448    0.688407   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0      0.465240     0.783552      0.216448  \n",
      "1      0.465240     0.783552      0.216448  \n",
      "2      0.467404     0.781534      0.218466  \n",
      "3      0.467404     0.781534      0.218466  \n",
      "4      0.467404     0.781534      0.218466  \n",
      "5      0.467404     0.781534      0.218466  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1  rbf_rmse  \\\n",
      "0   0.5   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "1   1.0   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "2   1.5   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "3   2.0   0.688462      0.46524    0.783552     0.216448  0.688462  0.465240   \n",
      "4   2.5   0.688462      0.46524    0.783552     0.216448  0.688213  0.465782   \n",
      "5   3.0   0.688462      0.46524    0.783552     0.216448  0.687964  0.466323   \n",
      "6   4.0   0.688462      0.46524    0.783552     0.216448  0.687715  0.466864   \n",
      "7   5.0   0.688462      0.46524    0.783552     0.216448  0.688910  0.466323   \n",
      "8  10.0   0.688462      0.46524    0.783552     0.216448  0.689339  0.467404   \n",
      "9  20.0   0.688462      0.46524    0.783552     0.216448  0.688156  0.467943   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.783552  0.216448  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "1  0.783552  0.216448  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "2  0.783552  0.216448  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "3  0.783552  0.216448  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "4  0.783047  0.216953  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "5  0.782543  0.217457  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "6  0.782038  0.217962  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "7  0.782543  0.217457  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "8  0.781534  0.218466  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "9  0.781029  0.218971  0.688462    0.46524  0.783552   0.216448      0.688462   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0         0.46524       0.783552        0.216448  \n",
      "1         0.46524       0.783552        0.216448  \n",
      "2         0.46524       0.783552        0.216448  \n",
      "3         0.46524       0.783552        0.216448  \n",
      "4         0.46524       0.783552        0.216448  \n",
      "5         0.46524       0.783552        0.216448  \n",
      "6         0.46524       0.783552        0.216448  \n",
      "7         0.46524       0.783552        0.216448  \n",
      "8         0.46524       0.783552        0.216448  \n",
      "9         0.46524       0.783552        0.216448  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "1     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "2     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "3     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "1        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "2        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "3        0.46524      0.783552       0.216448  0.688462    0.46524  0.783552   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.216448  0.688462   0.465240  0.783552   0.216448  (10, 10, 10)  \n",
      "1   0.216448  0.688462   0.465240  0.783552   0.216448     (5, 5, 5)  \n",
      "2   0.216448  0.688462   0.465240  0.783552   0.216448     (3, 3, 3)  \n",
      "3   0.216448  0.689339   0.467404  0.781534   0.218466  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "1     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "2     0.688462        0.46524      0.783552       0.216448     0.688462   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        0.46524      0.783552       0.216448  0.690075   0.473303  0.775984   \n",
      "1        0.46524      0.783552       0.216448  0.688462   0.465240  0.783552   \n",
      "2        0.46524      0.783552       0.216448  0.688462   0.465240  0.783552   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.224016  0.688831   0.468482  0.780525   0.219475  lbfgs  \n",
      "1   0.216448  0.688462   0.465240  0.783552   0.216448    sgd  \n",
      "2   0.216448  0.688462   0.465240  0.783552   0.216448   adam  \n",
      "df_NN\n",
      "5\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.251117   1.540571  0.244198   0.755802      0.251511   \n",
      "1    2  0.234100   1.578904  0.249748   0.750252      0.234024   \n",
      "2    3  0.352145   1.292101  0.402119   0.597881      0.352655   \n",
      "3    4  0.364378   1.219378  0.449041   0.550959      0.365436   \n",
      "4    5  0.369320   1.195982  0.464178   0.535822      0.370045   \n",
      "5    6  0.364237   1.204390  0.474773   0.525227      0.362368   \n",
      "6    7  0.372081   1.203342  0.450050   0.549950      0.371454   \n",
      "7    8  0.369638   1.187515  0.461150   0.538850      0.369516   \n",
      "8    9  0.373426   1.194716  0.438951   0.561049      0.373426   \n",
      "9   10  0.376028   1.201454  0.439455   0.560545      0.375960   \n",
      "10  11  0.373735   1.171474  0.477296   0.522704      0.373950   \n",
      "11  12  0.369615   1.163262  0.476791   0.523209      0.370413   \n",
      "12  13  0.371632   1.166078  0.480323   0.519677      0.371547   \n",
      "13  14  0.364231   1.127807  0.500000   0.500000      0.364139   \n",
      "14  15  0.365752   1.166943  0.487386   0.512614      0.366669   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0         1.540899       0.244702        0.755298    0.251117      1.540571   \n",
      "1         1.579223       0.250252        0.749748    0.234100      1.578904   \n",
      "2         1.291906       0.402624        0.597376    0.352145      1.292101   \n",
      "3         1.218343       0.450050        0.549950    0.364378      1.219378   \n",
      "4         1.195138       0.464682        0.535318    0.369320      1.195982   \n",
      "5         1.205437       0.473764        0.526236    0.364237      1.204390   \n",
      "6         1.204180       0.449546        0.550454    0.372081      1.203342   \n",
      "7         1.186877       0.461150        0.538850    0.369638      1.187515   \n",
      "8         1.194716       0.438951        0.561049    0.373426      1.194716   \n",
      "9         1.200824       0.439455        0.560545    0.376028      1.201454   \n",
      "10        1.170612       0.477800        0.522200    0.373735      1.171474   \n",
      "11        1.162394       0.477296        0.522704    0.369615      1.163262   \n",
      "12        1.165429       0.480323        0.519677    0.371632      1.166078   \n",
      "13        1.127135       0.500000        0.500000    0.364231      1.127807   \n",
      "14        1.166078       0.487891        0.512109    0.365752      1.166943   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.244198      0.755802  0.367702    1.314362   0.420787    0.579213  \n",
      "1      0.249748      0.750252  0.349839    1.305117   0.409183    0.590817  \n",
      "2      0.402119      0.597881  0.371330    1.231523   0.427851    0.572149  \n",
      "3      0.449041      0.550959  0.365134    1.177060   0.449041    0.550959  \n",
      "4      0.464178      0.535822  0.366113    1.159787   0.462159    0.537841  \n",
      "5      0.474773      0.525227  0.366961    1.147102   0.476791    0.523209  \n",
      "6      0.450050      0.549950  0.367423    1.157392   0.476287    0.523713  \n",
      "7      0.461150      0.538850  0.366203    1.145782   0.485873    0.514127  \n",
      "8      0.438951      0.561049  0.361463    1.137384   0.497477    0.502523  \n",
      "9      0.439455      0.560545  0.361417    1.133830   0.501514    0.498486  \n",
      "10     0.477296      0.522704  0.361417    1.133830   0.501514    0.498486  \n",
      "11     0.476791      0.523209  0.363498    1.126688   0.498486    0.501514  \n",
      "12     0.480323      0.519677  0.361007    1.133607   0.504036    0.495964  \n",
      "13     0.500000      0.500000  0.359176    1.126464   0.500000    0.500000  \n",
      "14     0.487386      0.512614  0.360226    1.133385   0.501009    0.498991  \n",
      "df_knn\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1       0.34801        1.109768       0.513118        0.486882   \n",
      "1    2       0.34801        1.109768       0.513118        0.486882   \n",
      "2    3       0.34801        1.109768       0.513118        0.486882   \n",
      "3    4       0.34801        1.109768       0.513118        0.486882   \n",
      "4    5       0.34801        1.109768       0.513118        0.486882   \n",
      "5    6       0.34801        1.109768       0.513118        0.486882   \n",
      "6    7       0.34801        1.109768       0.513118        0.486882   \n",
      "7    8       0.34801        1.109768       0.513118        0.486882   \n",
      "8    9       0.34801        1.109768       0.513118        0.486882   \n",
      "9   10       0.34801        1.109768       0.513118        0.486882   \n",
      "10  11       0.34801        1.109768       0.513118        0.486882   \n",
      "11  12       0.34801        1.109768       0.513118        0.486882   \n",
      "12  13       0.34801        1.109768       0.513118        0.486882   \n",
      "13  14       0.34801        1.109768       0.513118        0.486882   \n",
      "14  15       0.34801        1.109768       0.513118        0.486882   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm   sag_f1  \\\n",
      "0        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "1        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "2        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "3        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "4        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "5        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "6        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "7        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "8        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "9        0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "10       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "11       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "12       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "13       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "14       0.34801        1.109768       0.513118        0.486882  0.34801   \n",
      "\n",
      "    sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "1   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "2   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "3   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "4   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "5   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "6   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "7   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "8   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "9   1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "10  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "11  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "12  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "13  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "14  1.109768  0.513118  0.486882   0.34801    1.109768   0.513118    0.486882  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.348010      1.109768     0.513118      0.486882  0.348010   \n",
      "1           2    0.353856      1.107492     0.507568      0.492432  0.353797   \n",
      "2           3    0.354645      1.106353     0.512614      0.487386  0.352260   \n",
      "3           4    0.355825      1.112265     0.504036      0.495964  0.354958   \n",
      "4           5    0.354836      1.113172     0.504036      0.495964  0.357980   \n",
      "5           6    0.351350      1.116566     0.501009      0.498991  0.357865   \n",
      "6           7    0.350066      1.121751     0.498486      0.501514  0.367421   \n",
      "7           8    0.354508      1.132494     0.495459      0.504541  0.361269   \n",
      "8           9    0.356046      1.129371     0.495459      0.504541  0.361523   \n",
      "9          10    0.360097      1.128254     0.496468      0.503532  0.359581   \n",
      "10         11    0.358767      1.129818     0.496973      0.503027  0.360632   \n",
      "11         12    0.363176      1.130711     0.496468      0.503532  0.361408   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0    1.109768  0.513118   0.486882  \n",
      "1    1.106353  0.511100   0.488900  \n",
      "2    1.110677  0.509586   0.490414  \n",
      "3    1.112719  0.508073   0.491927  \n",
      "4    1.124671  0.507568   0.492432  \n",
      "5    1.128924  0.502523   0.497477  \n",
      "6    1.126688  0.506559   0.493441  \n",
      "7    1.127359  0.503532   0.496468  \n",
      "8    1.129148  0.502523   0.497477  \n",
      "9    1.138271  0.497982   0.502018  \n",
      "10   1.138049  0.498486   0.501514  \n",
      "11   1.139379  0.498486   0.501514  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.361948      1.124446     0.501514      0.498486   \n",
      "1            10    0.362596      1.123099     0.498486      0.501514   \n",
      "2            15    0.357994      1.122201     0.496468      0.503532   \n",
      "3            20    0.363370      1.118823     0.502523      0.497477   \n",
      "4            25    0.370824      1.123773     0.502523      0.497477   \n",
      "5            30    0.362125      1.125567     0.497982      0.502018   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.362732   1.134719  0.492936   0.507064  \n",
      "1  0.369161   1.134275  0.498991   0.501009  \n",
      "2  0.370110   1.124446  0.503532   0.496468  \n",
      "3  0.367610   1.117921  0.501009   0.498991  \n",
      "4  0.363365   1.123099  0.501514   0.498486  \n",
      "5  0.365779   1.121076  0.501514   0.498486  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.348675    1.109995   0.512614    0.487386    0.355248   \n",
      "1            10  0.348675    1.109995   0.512614    0.487386    0.355052   \n",
      "2            15  0.348675    1.109995   0.512614    0.487386    0.355150   \n",
      "3            20  0.348675    1.109995   0.512614    0.487386    0.355019   \n",
      "4            25  0.348675    1.109995   0.512614    0.487386    0.355444   \n",
      "5            30  0.348675    1.109995   0.512614    0.487386    0.351086   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0      1.107720     0.510595      0.489405  \n",
      "1      1.108175     0.510595      0.489405  \n",
      "2      1.107036     0.510595      0.489405  \n",
      "3      1.107948     0.510091      0.489909  \n",
      "4      1.110904     0.505045      0.494955  \n",
      "5      1.128924     0.495964      0.504036  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1  rbf_rmse  \\\n",
      "0   0.5    0.34801     1.109768    0.513118     0.486882  0.348904  1.109768   \n",
      "1   1.0    0.34801     1.109768    0.513118     0.486882  0.348215  1.108403   \n",
      "2   1.5    0.34801     1.109768    0.513118     0.486882  0.349316  1.108175   \n",
      "3   2.0    0.34801     1.109768    0.513118     0.486882  0.356800  1.107492   \n",
      "4   2.5    0.34801     1.109768    0.513118     0.486882  0.361520  1.109313   \n",
      "5   3.0    0.34801     1.109768    0.513118     0.486882  0.361883  1.111585   \n",
      "6   4.0    0.34801     1.109768    0.513118     0.486882  0.364537  1.120851   \n",
      "7   5.0    0.34801     1.109768    0.513118     0.486882  0.364281  1.121076   \n",
      "8  10.0    0.34801     1.109768    0.513118     0.486882  0.363992  1.122425   \n",
      "9  20.0    0.34801     1.109768    0.513118     0.486882  0.367933  1.121751   \n",
      "\n",
      "    rbf_acc  rbf_hamm  poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.513118  0.486882  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "1  0.511100  0.488900  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "2  0.511604  0.488396  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "3  0.508577  0.491423  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "4  0.509586  0.490414  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "5  0.508577  0.491423  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "6  0.505045  0.494955  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "7  0.504541  0.495459  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "8  0.503027  0.496973  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "9  0.504541  0.495459  0.34801   1.109768  0.513118   0.486882       0.34801   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0        1.109768       0.513118        0.486882  \n",
      "1        1.109768       0.513118        0.486882  \n",
      "2        1.109768       0.513118        0.486882  \n",
      "3        1.109768       0.513118        0.486882  \n",
      "4        1.109768       0.513118        0.486882  \n",
      "5        1.109768       0.513118        0.486882  \n",
      "6        1.109768       0.513118        0.486882  \n",
      "7        1.109768       0.513118        0.486882  \n",
      "8        1.109768       0.513118        0.486882  \n",
      "9        1.109768       0.513118        0.486882  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "1      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "2      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "3      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm  tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0       1.109768      0.513118       0.486882  0.34801   1.109768  0.513118   \n",
      "1       1.109768      0.513118       0.486882  0.34801   1.109768  0.513118   \n",
      "2       1.109768      0.513118       0.486882  0.34801   1.109768  0.513118   \n",
      "3       1.109768      0.513118       0.486882  0.34801   1.109768  0.513118   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.486882  0.358189   1.116114  0.504541   0.495459  (10, 10, 10)  \n",
      "1   0.486882  0.348010   1.109768  0.513118   0.486882     (5, 5, 5)  \n",
      "2   0.486882  0.348010   1.109768  0.513118   0.486882     (3, 3, 3)  \n",
      "3   0.486882  0.363714   1.124895  0.502018   0.497982  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "1      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "2      0.34801       1.109768      0.513118       0.486882      0.34801   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0       1.109768      0.513118       0.486882  0.368252   1.143578  0.496973   \n",
      "1       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "2       1.109768      0.513118       0.486882  0.348010   1.109768  0.513118   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.503027  0.358418   1.121976  0.496973   0.503027  lbfgs  \n",
      "1   0.486882  0.348010   1.109768  0.513118   0.486882    sgd  \n",
      "2   0.486882  0.358176   1.116114  0.505550   0.494450   adam  \n",
      "df_NN\n",
      "10\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.135484   3.285905  0.126135   0.873865      0.135330   \n",
      "1    2  0.112136   3.313200  0.114026   0.885974      0.112439   \n",
      "2    3  0.164891   2.550202  0.201312   0.798688      0.164968   \n",
      "3    4  0.168402   2.480397  0.211907   0.788093      0.168632   \n",
      "4    5  0.174027   2.470410  0.218971   0.781029      0.173770   \n",
      "5    6  0.168204   2.389326  0.224016   0.775984      0.168189   \n",
      "6    7  0.173402   2.375986  0.226539   0.773461      0.173044   \n",
      "7    8  0.176317   2.362676  0.229062   0.770938      0.176455   \n",
      "8    9  0.178797   2.342194  0.235621   0.764379      0.178774   \n",
      "9   10  0.182621   2.345961  0.238648   0.761352      0.182560   \n",
      "10  11  0.185609   2.296182  0.241171   0.758829      0.184744   \n",
      "11  12  0.188229   2.300134  0.240666   0.759334      0.188532   \n",
      "12  13  0.191427   2.287817  0.247730   0.752270      0.192315   \n",
      "13  14  0.187993   2.301450  0.245711   0.754289      0.188055   \n",
      "14  15  0.187150   2.304079  0.245711   0.754289      0.186647   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0         3.286827       0.126135        0.873865    0.135484      3.285905   \n",
      "1         3.314266       0.114531        0.885469    0.112136      3.313200   \n",
      "2         2.551686       0.201312        0.798688    0.164891      2.550202   \n",
      "3         2.480397       0.211907        0.788093    0.168402      2.480397   \n",
      "4         2.472962       0.218466        0.781534    0.174027      2.470410   \n",
      "5         2.390909       0.224016        0.775984    0.168204      2.389326   \n",
      "6         2.377366       0.226034        0.773966    0.173402      2.375986   \n",
      "7         2.362676       0.229062        0.770938    0.176317      2.362676   \n",
      "8         2.341871       0.235621        0.764379    0.178797      2.342194   \n",
      "9         2.344455       0.238648        0.761352    0.182621      2.345961   \n",
      "10        2.296182       0.240161        0.759839    0.185609      2.296182   \n",
      "11        2.296621       0.240666        0.759334    0.188229      2.300134   \n",
      "12        2.288258       0.248739        0.751261    0.191427      2.287817   \n",
      "13        2.301559       0.245711        0.754289    0.187993      2.301450   \n",
      "14        2.303969       0.245207        0.754793    0.187150      2.304079   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.126135      0.873865  0.168454    2.659351   0.220989    0.779011  \n",
      "1      0.114026      0.885974  0.148358    2.672599   0.220484    0.779516  \n",
      "2      0.201312      0.798688  0.176397    2.543863   0.206862    0.793138  \n",
      "3      0.211907      0.788093  0.174939    2.538304   0.206862    0.793138  \n",
      "4      0.218971      0.781029  0.181440    2.408570   0.213925    0.786075  \n",
      "5      0.224016      0.775984  0.185603    2.334426   0.234612    0.765388  \n",
      "6      0.226539      0.773461  0.192144    2.324680   0.249243    0.750757  \n",
      "7      0.229062      0.770938  0.190026    2.324029   0.253784    0.746216  \n",
      "8      0.235621      0.764379  0.190763    2.380865   0.244702    0.755298  \n",
      "9      0.238648      0.761352  0.183185    2.411815   0.270434    0.729566  \n",
      "10     0.241171      0.758829  0.171045    2.437100   0.262361    0.737639  \n",
      "11     0.240666      0.759334  0.177112    2.284617   0.243693    0.756307  \n",
      "12     0.247730      0.752270  0.182235    2.291123   0.250252    0.749748  \n",
      "13     0.245711      0.754289  0.178378    2.422460   0.260848    0.739152  \n",
      "14     0.245711      0.754289  0.166973    2.445470   0.261857    0.738143  \n",
      "df_knn\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1      0.143676        2.438548       0.276993        0.723007   \n",
      "1    2      0.145117        2.437410       0.277497        0.722503   \n",
      "2    3      0.147338        2.431607       0.278507        0.721493   \n",
      "3    4      0.147338        2.431607       0.278507        0.721493   \n",
      "4    5      0.147338        2.431607       0.278507        0.721493   \n",
      "5    6      0.147338        2.431607       0.278507        0.721493   \n",
      "6    7      0.147338        2.431607       0.278507        0.721493   \n",
      "7    8      0.147338        2.431607       0.278507        0.721493   \n",
      "8    9      0.147338        2.431607       0.278507        0.721493   \n",
      "9   10      0.147338        2.431607       0.278507        0.721493   \n",
      "10  11      0.147338        2.431607       0.278507        0.721493   \n",
      "11  12      0.147338        2.431607       0.278507        0.721493   \n",
      "12  13      0.147338        2.431607       0.278507        0.721493   \n",
      "13  14      0.147338        2.431607       0.278507        0.721493   \n",
      "14  15      0.147338        2.431607       0.278507        0.721493   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "1       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "2       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "3       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "4       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "5       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "6       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "7       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "8       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "9       0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "10      0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "11      0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "12      0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "13      0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "14      0.147338        2.432126       0.278507        0.721493  0.147338   \n",
      "\n",
      "    sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "1   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "2   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "3   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "4   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "5   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "6   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "7   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "8   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "9   2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "10  2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "11  2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "12  2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "13  2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "14  2.432126  0.278507  0.721493  0.147338    2.432126   0.278507    0.721493  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.142292      2.435650     0.274975      0.725025  0.143013   \n",
      "1           2    0.142292      2.435650     0.274975      0.725025  0.141561   \n",
      "2           3    0.133994      2.443509     0.273461      0.726539  0.142930   \n",
      "3           4    0.137652      2.444025     0.274470      0.725530  0.161059   \n",
      "4           5    0.138477      2.442476     0.272452      0.727548  0.157153   \n",
      "5           6    0.145162      2.438652     0.274470      0.725530  0.151073   \n",
      "6           7    0.147550      2.431400     0.273966      0.726034  0.170334   \n",
      "7           8    0.152713      2.427038     0.272957      0.727043  0.177238   \n",
      "8           9    0.160827      2.422252     0.276993      0.723007  0.175234   \n",
      "9          10    0.162102      2.425583     0.275984      0.724016  0.175469   \n",
      "10         11    0.161040      2.428597     0.274470      0.725530  0.180457   \n",
      "11         12    0.163661      2.423398     0.275479      0.724521  0.179867   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0    2.437410  0.278002   0.721998  \n",
      "1    2.434407  0.276488   0.723512  \n",
      "2    2.438135  0.272957   0.727043  \n",
      "3    2.411606  0.274975   0.725025  \n",
      "4    2.416622  0.272957   0.727043  \n",
      "5    2.430258  0.272957   0.727043  \n",
      "6    2.408989  0.270938   0.729062  \n",
      "7    2.412652  0.275479   0.724521  \n",
      "8    2.425063  0.273461   0.726539  \n",
      "9    2.435857  0.273966   0.726034  \n",
      "10   2.430673  0.274975   0.725025  \n",
      "11   2.424959  0.274470   0.725530  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.195811      2.399020     0.275984      0.724016   \n",
      "1            10    0.181662      2.409827     0.267407      0.732593   \n",
      "2            15    0.179633      2.397968     0.263875      0.736125   \n",
      "3            20    0.186665      2.401858     0.274975      0.725025   \n",
      "4            25    0.173522      2.413593     0.263370      0.736630   \n",
      "5            30    0.176421      2.421523     0.267407      0.732593   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.183030   2.399756  0.267911   0.732089  \n",
      "1  0.173633   2.433785  0.260848   0.739152  \n",
      "2  0.181756   2.412129  0.272957   0.727043  \n",
      "3  0.180195   2.408570  0.269425   0.730575  \n",
      "4  0.177666   2.433370  0.270434   0.729566  \n",
      "5  0.179597   2.428285  0.268920   0.731080  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.107667    2.134007   0.236125    0.763875    0.146292   \n",
      "1            10  0.117744    2.459767   0.271948    0.728052    0.133205   \n",
      "2            15  0.117744    2.459767   0.271948    0.728052    0.146446   \n",
      "3            20  0.117744    2.459767   0.271948    0.728052    0.146928   \n",
      "4            25  0.134219    2.443612   0.275984    0.724016    0.149718   \n",
      "5            30  0.157143    2.403118   0.275479    0.724521    0.158112   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0      2.437514     0.280020      0.719980  \n",
      "1      2.439686     0.268416      0.731584  \n",
      "2      2.438652     0.274470      0.725530  \n",
      "3      2.446089     0.273461      0.726539  \n",
      "4      2.444335     0.274975      0.725025  \n",
      "5      2.424750     0.271443      0.728557  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1  rbf_rmse  \\\n",
      "0   0.5   0.115517      2.46069    0.270938     0.729062  0.163274  2.411292   \n",
      "1   1.0   0.115517      2.46069    0.270938     0.729062  0.166391  2.413488   \n",
      "2   1.5   0.115517      2.46069    0.270938     0.729062  0.170859  2.408047   \n",
      "3   2.0   0.115517      2.46069    0.270938     0.729062  0.172193  2.400912   \n",
      "4   2.5   0.115517      2.46069    0.270938     0.729062  0.171929  2.402593   \n",
      "5   3.0   0.115517      2.46069    0.270938     0.729062  0.172524  2.406579   \n",
      "6   4.0   0.115517      2.46069    0.270938     0.729062  0.175199  2.406265   \n",
      "7   5.0   0.115517      2.46069    0.270938     0.729062  0.176870  2.402278   \n",
      "8  10.0   0.115517      2.46069    0.270938     0.729062  0.178005  2.414846   \n",
      "9  20.0   0.115517      2.46069    0.270938     0.729062  0.177162  2.414324   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.278507  0.721493  0.168035   2.395442  0.279011   0.720989      0.148208   \n",
      "1  0.274470  0.725530  0.171511   2.406475  0.282038   0.717962      0.148203   \n",
      "2  0.275479  0.724521  0.171683   2.406055  0.282543   0.717457      0.148203   \n",
      "3  0.274470  0.725530  0.169998   2.408675  0.280525   0.719475      0.148203   \n",
      "4  0.273461  0.726539  0.171764   2.408570  0.281534   0.718466      0.148203   \n",
      "5  0.272957  0.727043  0.171764   2.408570  0.281534   0.718466      0.148203   \n",
      "6  0.273966  0.726034  0.171805   2.409408  0.281534   0.718466      0.148203   \n",
      "7  0.274975  0.725025  0.171805   2.409408  0.281534   0.718466      0.148203   \n",
      "8  0.274470  0.725530  0.171805   2.409408  0.281534   0.718466      0.148203   \n",
      "9  0.273966  0.726034  0.171747   2.408884  0.281534   0.718466      0.148203   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0        2.438031       0.282038        0.717962  \n",
      "1        2.437721       0.282038        0.717962  \n",
      "2        2.437721       0.282038        0.717962  \n",
      "3        2.437721       0.282038        0.717962  \n",
      "4        2.437721       0.282038        0.717962  \n",
      "5        2.437721       0.282038        0.717962  \n",
      "6        2.437721       0.282038        0.717962  \n",
      "7        2.437721       0.282038        0.717962  \n",
      "8        2.437721       0.282038        0.717962  \n",
      "9        2.437721       0.282038        0.717962  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.131010       2.446295      0.272957       0.727043     0.115517   \n",
      "1     0.141786       2.442580      0.279011       0.720989     0.115517   \n",
      "2     0.133214       2.449078      0.268416       0.731584     0.115517   \n",
      "3     0.156004       2.422356      0.279516       0.720484     0.115517   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        2.46069      0.270938       0.729062  0.156241   2.412652  0.280525   \n",
      "1        2.46069      0.270938       0.729062  0.130923   2.449696  0.275479   \n",
      "2        2.46069      0.270938       0.729062  0.115362   2.459049  0.269929   \n",
      "3        2.46069      0.270938       0.729062  0.169438   2.388693  0.277497   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.719475  0.152321   2.422460  0.275984   0.724016  (10, 10, 10)  \n",
      "1   0.724521  0.115517   2.460690  0.270938   0.729062     (5, 5, 5)  \n",
      "2   0.730071  0.127274   2.450828  0.271948   0.728052     (3, 3, 3)  \n",
      "3   0.722503  0.176412   2.415682  0.273966   0.726034  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.146558       2.432437      0.279516       0.720484     0.115517   \n",
      "1     0.141368       2.438031      0.272957       0.727043     0.115517   \n",
      "2     0.149864       2.431504      0.281534       0.718466     0.115517   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0        2.46069      0.270938       0.729062  0.158169   2.455559  0.271443   \n",
      "1        2.46069      0.270938       0.729062  0.137690   2.446501  0.278002   \n",
      "2        2.46069      0.270938       0.729062  0.160526   2.412338  0.274470   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.728557  0.146864   2.448872  0.269425   0.730575  lbfgs  \n",
      "1   0.721998  0.117613   2.458126  0.271443   0.728557    sgd  \n",
      "2   0.725530  0.145685   2.424022  0.276993   0.723007   adam  \n",
      "df_NN\n",
      "100\n",
      "     K   auto_f1  auto_rmse  auto_acc  auto_hamm  ball_tree_f1  \\\n",
      "0    1  0.008701  33.652547  0.011100   0.988900      0.008717   \n",
      "1    2  0.007425  33.730890  0.008577   0.991423      0.007429   \n",
      "2    3  0.007069  34.260149  0.008577   0.991423      0.007073   \n",
      "3    4  0.007923  26.733577  0.018163   0.981837      0.007929   \n",
      "4    5  0.007269  26.940913  0.018163   0.981837      0.008085   \n",
      "5    6  0.007629  27.134824  0.018163   0.981837      0.007631   \n",
      "6    7  0.008329  27.675292  0.017154   0.982846      0.008332   \n",
      "7    8  0.008370  27.718393  0.017154   0.982846      0.009177   \n",
      "8    9  0.008628  27.556162  0.017154   0.982846      0.009495   \n",
      "9   10  0.008626  31.990712  0.018668   0.981332      0.009475   \n",
      "10  11  0.010534  26.862311  0.021191   0.978809      0.011367   \n",
      "11  12  0.010371  26.119872  0.020686   0.979314      0.010396   \n",
      "12  13  0.010142  25.786831  0.021191   0.978809      0.010190   \n",
      "13  14  0.011319  24.699680  0.022200   0.977800      0.011359   \n",
      "14  15  0.012916  24.824480  0.023713   0.976287      0.012073   \n",
      "\n",
      "    ball_tree_rmse  ball_tree_acc  ball_tree_hamm  kd_tree_f1  kd_tree_rmse  \\\n",
      "0        33.663325       0.011100        0.988900    0.008701     33.652547   \n",
      "1        33.739939       0.008577        0.991423    0.007425     33.730890   \n",
      "2        34.255392       0.008577        0.991423    0.007069     34.260149   \n",
      "3        26.724536       0.018163        0.981837    0.007923     26.733577   \n",
      "4        26.935772       0.018668        0.981332    0.007269     26.940913   \n",
      "5        27.145737       0.018163        0.981837    0.007629     27.134824   \n",
      "6        27.685992       0.017154        0.982846    0.008329     27.675292   \n",
      "7        27.744646       0.017659        0.982341    0.008370     27.718393   \n",
      "8        27.580640       0.017659        0.982341    0.008628     27.556162   \n",
      "9        32.018087       0.019173        0.980827    0.008626     31.990712   \n",
      "10       26.873569       0.021695        0.978305    0.010534     26.862311   \n",
      "11       26.134191       0.020686        0.979314    0.010371     26.119872   \n",
      "12       25.805324       0.021191        0.978809    0.010142     25.786831   \n",
      "13       24.716924       0.022200        0.977800    0.011319     24.699680   \n",
      "14       24.857617       0.023209        0.976791    0.012916     24.824480   \n",
      "\n",
      "    kd_tree_acc  kd_tree_hamm  brute_f1  brute_rmse  brute_acc  brute_hamm  \n",
      "0      0.011100      0.988900  0.015579   27.264532   0.028759    0.971241  \n",
      "1      0.008577      0.991423  0.013348   27.320629   0.028254    0.971746  \n",
      "2      0.008577      0.991423  0.010610   27.535126   0.027245    0.972755  \n",
      "3      0.018163      0.981837  0.010110   28.214786   0.024723    0.975277  \n",
      "4      0.018163      0.981837  0.010194   27.880140   0.024723    0.975277  \n",
      "5      0.018163      0.981837  0.009211   27.729530   0.025227    0.974773  \n",
      "6      0.017154      0.982846  0.009538   27.650122   0.026236    0.973764  \n",
      "7      0.017154      0.982846  0.009595   27.761699   0.026741    0.973259  \n",
      "8      0.017154      0.982846  0.010995   27.033727   0.027245    0.972755  \n",
      "9      0.018668      0.981332  0.011317   26.138989   0.027245    0.972755  \n",
      "10     0.021191      0.978809  0.009967   26.165284   0.026236    0.973764  \n",
      "11     0.020686      0.979314  0.009342   26.926845   0.025227    0.974773  \n",
      "12     0.021191      0.978809  0.009113   26.308252   0.024723    0.975277  \n",
      "13     0.022200      0.977800  0.010180   26.020852   0.026236    0.973764  \n",
      "14     0.023713      0.976287  0.010409   26.141585   0.026741    0.973259  \n",
      "df_knn\n",
      "     C  liblinear_f1  liblinear_rmse  liblinear_acc  liblinear_hamm  \\\n",
      "0    1      0.012091       22.854848       0.029263        0.970737   \n",
      "1    2      0.011501       22.925735       0.028254        0.971746   \n",
      "2    3      0.011538       22.929123       0.028254        0.971746   \n",
      "3    4      0.011576       22.884521       0.028254        0.971746   \n",
      "4    5      0.011576       22.884521       0.028254        0.971746   \n",
      "5    6      0.011576       22.945599       0.028254        0.971746   \n",
      "6    7      0.011576       22.945599       0.028254        0.971746   \n",
      "7    8      0.011576       22.962359       0.028254        0.971746   \n",
      "8    9      0.011576       22.938968       0.028254        0.971746   \n",
      "9   10      0.011576       22.938968       0.028254        0.971746   \n",
      "10  11      0.011576       22.938968       0.028254        0.971746   \n",
      "11  12      0.011576       22.938968       0.028254        0.971746   \n",
      "12  13      0.011576       22.938968       0.028254        0.971746   \n",
      "13  14      0.011576       22.938968       0.028254        0.971746   \n",
      "14  15      0.011576       22.938968       0.028254        0.971746   \n",
      "\n",
      "    newton-cg_f1  newton-cg_rmse  newton-cg_acc  newton-cg_hamm    sag_f1  \\\n",
      "0       0.012053       22.894639       0.028759        0.971241  0.012053   \n",
      "1       0.011501       22.925735       0.028254        0.971746  0.011501   \n",
      "2       0.011581       22.882923       0.028254        0.971746  0.011581   \n",
      "3       0.011581       22.944005       0.028254        0.971746  0.011581   \n",
      "4       0.011581       22.960766       0.028254        0.971746  0.011581   \n",
      "5       0.011581       22.960766       0.028254        0.971746  0.011581   \n",
      "6       0.011581       22.937374       0.028254        0.971746  0.011581   \n",
      "7       0.011581       22.937374       0.028254        0.971746  0.011581   \n",
      "8       0.011581       22.937374       0.028254        0.971746  0.011581   \n",
      "9       0.011344       22.934602       0.027245        0.972755  0.011344   \n",
      "10      0.011344       22.934602       0.027245        0.972755  0.011344   \n",
      "11      0.011344       22.934602       0.027245        0.972755  0.011344   \n",
      "12      0.011344       22.934602       0.027245        0.972755  0.011344   \n",
      "13      0.011344       22.934602       0.027245        0.972755  0.011344   \n",
      "14      0.011344       22.934602       0.027245        0.972755  0.011344   \n",
      "\n",
      "     sag_rmse   sag_acc  sag_hamm  lbfgs_f1  lbfgs_rmse  lbfgs_acc  lbfgs_hamm  \n",
      "0   22.894639  0.028759  0.971241  0.012208   22.843675   0.029263    0.970737  \n",
      "1   22.925735  0.028254  0.971746  0.011501   22.925735   0.028254    0.971746  \n",
      "2   22.882923  0.028254  0.971746  0.011581   22.882923   0.028254    0.971746  \n",
      "3   22.944005  0.028254  0.971746  0.011581   22.944005   0.028254    0.971746  \n",
      "4   22.960766  0.028254  0.971746  0.011581   22.960766   0.028254    0.971746  \n",
      "5   22.960766  0.028254  0.971746  0.011581   22.960766   0.028254    0.971746  \n",
      "6   22.937374  0.028254  0.971746  0.011581   22.937374   0.028254    0.971746  \n",
      "7   22.937374  0.028254  0.971746  0.011581   22.937374   0.028254    0.971746  \n",
      "8   22.937374  0.028254  0.971746  0.011581   22.937374   0.028254    0.971746  \n",
      "9   22.934602  0.027245  0.972755  0.011344   22.934602   0.027245    0.972755  \n",
      "10  22.934602  0.027245  0.972755  0.011344   22.934602   0.027245    0.972755  \n",
      "11  22.934602  0.027245  0.972755  0.011344   22.934602   0.027245    0.972755  \n",
      "12  22.934602  0.027245  0.972755  0.011344   22.934602   0.027245    0.972755  \n",
      "13  22.934602  0.027245  0.972755  0.011344   22.934602   0.027245    0.972755  \n",
      "14  22.934602  0.027245  0.972755  0.011344   22.934602   0.027245    0.972755  \n",
      "df_LogR\n",
      "    max_depth  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm   gini_f1  \\\n",
      "0           1    0.002654     22.325961     0.026741      0.973259  0.002654   \n",
      "1           2    0.005867     22.540377     0.030272      0.969728  0.001755   \n",
      "2           3    0.007308     22.662576     0.026741      0.973259  0.003075   \n",
      "3           4    0.009192     22.996545     0.026236      0.973764  0.005530   \n",
      "4           5    0.010911     23.105438     0.028254      0.971746  0.007559   \n",
      "5           6    0.014813     24.087819     0.029768      0.970232  0.008106   \n",
      "6           7    0.012271     24.171113     0.025732      0.974268  0.008021   \n",
      "7           8    0.016294     24.224178     0.028759      0.971241  0.009477   \n",
      "8           9    0.014863     23.966972     0.027750      0.972250  0.009073   \n",
      "9          10    0.015131     23.951526     0.027750      0.972250  0.010647   \n",
      "10         11    0.014487     23.969456     0.027245      0.972755  0.011544   \n",
      "11         12    0.014972     23.935753     0.027750      0.972250  0.011605   \n",
      "\n",
      "    gini_rmse  gini_acc  gini_hamm  \n",
      "0   22.325961  0.026741   0.973259  \n",
      "1   22.402035  0.025732   0.974268  \n",
      "2   22.555929  0.026741   0.973259  \n",
      "3   22.606648  0.027750   0.972250  \n",
      "4   22.650172  0.028759   0.971241  \n",
      "5   22.953272  0.026741   0.973259  \n",
      "6   23.202928  0.025732   0.974268  \n",
      "7   23.271540  0.026236   0.973764  \n",
      "8   23.551402  0.025732   0.974268  \n",
      "9   24.026852  0.030272   0.969728  \n",
      "10  23.746103  0.027750   0.972250  \n",
      "11  25.465029  0.028254   0.971746  \n",
      "df_DT\n",
      "   n_estimators  entropy_f1  entropy_rmse  entropy_acc  entropy_hamm  \\\n",
      "0             5    0.018029     28.314963     0.031282      0.968718   \n",
      "1            10    0.013853     24.851029     0.028759      0.971241   \n",
      "2            15    0.013149     23.506242     0.025732      0.974268   \n",
      "3            20    0.015379     23.435163     0.028254      0.971746   \n",
      "4            25    0.016404     23.470079     0.030272      0.969728   \n",
      "5            30    0.015896     24.204196     0.028759      0.971241   \n",
      "\n",
      "    gini_f1  gini_rmse  gini_acc  gini_hamm  \n",
      "0  0.012412  30.710663  0.021191   0.978809  \n",
      "1  0.011123  25.324384  0.021191   0.978809  \n",
      "2  0.011326  24.319632  0.023713   0.976287  \n",
      "3  0.010434  24.576360  0.024218   0.975782  \n",
      "4  0.013374  24.711494  0.027245   0.972755  \n",
      "5  0.012541  23.625622  0.024723   0.975277  \n",
      "df_RF\n",
      "   n_estimators  SAMME_f1  SAMME_rmse  SAMME_acc  SAMME_hamm  SAMME.R_f1  \\\n",
      "0             5  0.002327   23.623401   0.026741    0.973259    0.007296   \n",
      "1            10  0.001779   64.877300   0.030272    0.969728    0.006363   \n",
      "2            15  0.001779   64.877300   0.030272    0.969728    0.005972   \n",
      "3            20  0.001779   64.877300   0.030272    0.969728    0.008442   \n",
      "4            25  0.001775   64.377125   0.029768    0.970232    0.007789   \n",
      "5            30  0.001775   64.377125   0.029768    0.970232    0.008853   \n",
      "\n",
      "   SAMME.R_rmse  SAMME.R_acc  SAMME.R_hamm  \n",
      "0     22.563678     0.031786      0.968214  \n",
      "1     24.297122     0.023209      0.976791  \n",
      "2     23.861260     0.026741      0.973259  \n",
      "3     24.167094     0.024723      0.975277  \n",
      "4     27.270841     0.021695      0.978305  \n",
      "5     29.361048     0.024218      0.975782  \n",
      "df_AdaB\n",
      "      C  linear_f1  linear_rmse  linear_acc  linear_hamm    rbf_f1   rbf_rmse  \\\n",
      "0   0.5   0.006048    23.151826    0.026741     0.973259  0.005681  23.078990   \n",
      "1   1.0   0.006659    23.148241    0.027750     0.972250  0.008388  23.147293   \n",
      "2   1.5   0.009018    23.076191    0.028254     0.971746  0.013988  24.160256   \n",
      "3   2.0   0.008101    23.070637    0.027750     0.972250  0.014023  24.061129   \n",
      "4   2.5   0.009006    23.086989    0.027750     0.972250  0.013732  23.994281   \n",
      "5   3.0   0.009012    23.089787    0.027750     0.972250  0.015021  24.111026   \n",
      "6   4.0   0.009929    23.105514    0.028254     0.971746  0.012871  24.242250   \n",
      "7   5.0   0.009928    23.106824    0.028254     0.971746  0.012935  24.256149   \n",
      "8  10.0   0.009870    23.086356    0.028254     0.971746  0.013825  24.052058   \n",
      "9  20.0   0.010026    23.215417    0.027245     0.972755  0.013847  24.010225   \n",
      "\n",
      "    rbf_acc  rbf_hamm   poly_f1  poly_rmse  poly_acc  poly_hamm  LinearSVC_f1  \\\n",
      "0  0.024723  0.975277  0.012330  23.169711  0.027750   0.972250       0.01149   \n",
      "1  0.025732  0.974268  0.014230  23.068078  0.028759   0.971241       0.01149   \n",
      "2  0.029263  0.970737  0.016105  23.089131  0.030272   0.969728       0.01149   \n",
      "3  0.029263  0.970737  0.014804  23.107872  0.029263   0.970737       0.01149   \n",
      "4  0.029263  0.970737  0.014905  23.114673  0.029768   0.970232       0.01149   \n",
      "5  0.030272  0.969728  0.015092  23.130863  0.030272   0.969728       0.01149   \n",
      "6  0.028759  0.971241  0.013992  23.247907  0.029768   0.970232       0.01149   \n",
      "7  0.028759  0.971241  0.013694  23.154169  0.029263   0.970737       0.01149   \n",
      "8  0.029263  0.970737  0.013663  23.155302  0.029263   0.970737       0.01149   \n",
      "9  0.029263  0.970737  0.014700  23.149331  0.029768   0.970232       0.01149   \n",
      "\n",
      "   LinearSVC_rmse  LinearSVC_acc  LinearSVC_hamm  \n",
      "0       22.872392       0.029263        0.970737  \n",
      "1       22.872392       0.029263        0.970737  \n",
      "2       22.872392       0.029263        0.970737  \n",
      "3       22.872392       0.029263        0.970737  \n",
      "4       22.872392       0.029263        0.970737  \n",
      "5       22.872392       0.029263        0.970737  \n",
      "6       22.872392       0.029263        0.970737  \n",
      "7       22.872392       0.029263        0.970737  \n",
      "8       22.872392       0.029263        0.970737  \n",
      "9       22.872392       0.029263        0.970737  \n",
      "df_SVM\n",
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.009153      23.250121      0.026236       0.973764     0.001499   \n",
      "1     0.007668      23.010516      0.028254       0.971746     0.001499   \n",
      "2     0.007375      22.977219      0.024723       0.975277     0.001499   \n",
      "3     0.010966      23.130612      0.026236       0.973764     0.001499   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0      22.486065       0.02775        0.97225  0.009954  22.793174  0.027750   \n",
      "1      22.486065       0.02775        0.97225  0.006843  23.216895  0.026236   \n",
      "2      22.486065       0.02775        0.97225  0.001499  22.486065  0.027750   \n",
      "3      22.486065       0.02775        0.97225  0.014452  23.386057  0.026741   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm        Layers  \n",
      "0   0.972250  0.010545  23.305759  0.026741   0.973259  (10, 10, 10)  \n",
      "1   0.973764  0.004967  22.798430  0.030272   0.969728     (5, 5, 5)  \n",
      "2   0.972250  0.007087  22.786576  0.032291   0.967709     (3, 3, 3)  \n",
      "3   0.973259  0.009736  24.521166  0.026741   0.973259  (20, 20, 20)  \n",
      "df_NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_f1  identity_rmse  identity_acc  identity_hamm  logistic_f1  \\\n",
      "0     0.011267      23.231842      0.026741       0.973259     0.001499   \n",
      "1     0.008578      23.053857      0.031282       0.968718     0.001499   \n",
      "2     0.011167      23.138812      0.027245       0.972755     0.001499   \n",
      "\n",
      "   logistic_rmse  logistic_acc  logistic_hamm   tanh_f1  tanh_rmse  tanh_acc  \\\n",
      "0      22.486065       0.02775        0.97225  0.012704  23.316830  0.026741   \n",
      "1      22.486065       0.02775        0.97225  0.003401  22.491225  0.029263   \n",
      "2      22.486065       0.02775        0.97225  0.010745  22.972772  0.024723   \n",
      "\n",
      "   tanh_hamm   relu_f1  relu_rmse  relu_acc  relu_hamm Solver  \n",
      "0   0.973259  0.009688  25.098444  0.026236   0.973764  lbfgs  \n",
      "1   0.970737  0.004869  22.892578  0.030272   0.969728    sgd  \n",
      "2   0.975277  0.012027  23.196415  0.027750   0.972250   adam  \n",
      "df_NN\n"
     ]
    }
   ],
   "source": [
    "scale_list = [2, 5, 10, 100]\n",
    "file_name = \"model_summary_w_pca_8_final.xlsx\"\n",
    "for scale in scale_list:\n",
    "    print(scale)\n",
    "    Y_train, Y_dev = assign_y(scale)\n",
    "    df_knn = knn_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "#     df_NB = NB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_MNB = MNB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_GNB = GNB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_logR = LogR_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "    df_DT = DT_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "    df_RF = RF_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "    df_AdaB = AdaB_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "    df_SVM = SVM_models(train_data2, Y_train, dev_data2)\n",
    "    df_NN1 = NN_models(train_data2, Y_train, dev_data2, Y_dev, \"L\")\n",
    "    df_NN2 = NN_models(train_data2, Y_train, dev_data2, Y_dev, \"S\")\n",
    "\n",
    "    wrt_excel(file_name, \"knn-\"+str(scale), df_knn)\n",
    "#     wrt_excel(file_name, \"NB-\"+str(scale), df_NB)    \n",
    "#     wrt_excel(file_name, \"MNB-\"+str(scale), df_MNB)\n",
    "#     wrt_excel(file_name, \"GNB-\"+str(scale), df_GNB)\n",
    "    wrt_excel(file_name, \"logR-\"+str(scale), df_logR)\n",
    "    wrt_excel(file_name, \"DT-\"+str(scale), df_DT)\n",
    "    wrt_excel(file_name, \"RF-\"+str(scale), df_RF)\n",
    "    wrt_excel(file_name, \"AdaB-\"+str(scale), df_AdaB)\n",
    "    wrt_excel(file_name, \"SVM-\"+str(scale), df_SVM)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"L\", df_NN1)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"S\", df_NN2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
