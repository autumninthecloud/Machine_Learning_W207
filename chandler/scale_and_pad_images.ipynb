{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa16da0-7a62-4534-847d-c58283efd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ebdea6-acb3-454a-8b73-d06d670cbf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
       "0          0      1        0      0          0     0     0           63  \n",
       "1          0      0        0      0          0     0     0           42  \n",
       "2          0      0        0      1          1     0     0           28  \n",
       "3          0      0        0      0          0     0     0           15  \n",
       "4          0      1        0      0          0     0     0           72  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9fa8c80-9a0a-4202-b3de-a7f072bd89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "  image = np.array(image)\n",
    "  # reshape into shape [batch_size, height, width, num_channels]\n",
    "  img_reshaped = tf.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]])\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  image = tf.image.convert_image_dtype(img_reshaped, tf.float32)\n",
    "  return image\n",
    "\n",
    "def load_image_from_path(path):\n",
    "  \"\"\"Returns an image with shape [1, height, width, num_channels].\"\"\"\n",
    "  image = Image.open(path)\n",
    "  image = preprocess_image(image)\n",
    "  return image\n",
    "\n",
    "def load_image(image_url, image_size=256, dynamic_size=False, max_dynamic_size=512):\n",
    "  \"\"\"Loads and preprocesses images.\"\"\"\n",
    "  # Cache image file locally.\n",
    "  if image_url.startswith('https://'):\n",
    "    img = load_image_from_path(image_url)\n",
    "  else:\n",
    "    fd = tf.io.gfile.GFile(image_url, 'rb')\n",
    "    img = preprocess_image(Image.open(fd))\n",
    "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
    "  img_raw = img\n",
    "  if tf.reduce_max(img) > 1.0:\n",
    "    img = img / 255.\n",
    "  if len(img.shape) == 3:\n",
    "    img = tf.stack([img, img, img], axis=-1)\n",
    "  if not dynamic_size:\n",
    "    img = tf.image.resize_with_pad(img, image_size, image_size)\n",
    "  elif img.shape[1] > max_dynamic_size or img.shape[2] > max_dynamic_size:\n",
    "    img = tf.image.resize_with_pad(img, max_dynamic_size, max_dynamic_size)\n",
    "  return img\n",
    "\n",
    "def show_image(image, title=''):\n",
    "  image_size = image.shape[1]\n",
    "  w = (image_size * 6) // 320\n",
    "  plt.figure(figsize=(w, w))\n",
    "  plt.imshow(image[0], aspect='equal')\n",
    "  plt.axis('off')\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "def save_image(image, name):\n",
    "  image_size = image.shape[1]\n",
    "  w = (image_size * 6) // 320\n",
    "  plt.figure(figsize=(w, w))\n",
    "  plt.imshow(image[0], aspect='equal')\n",
    "  plt.axis('off')\n",
    "  plt.savefig(name,pad_inches=0,bbox_inches='tight')\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979e211e-76d1-494a-8db4-7094da28a7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 01:00:43.457561: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "image_path = \"../data/train/\" + df.Id[0] + \".jpg\"\n",
    "image = load_image(image_path, 240, 240, 240)\n",
    "save_image(image, \"test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052854d1-1a0e-4b1a-88a6-bc2a233a04ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "        ... \n",
       "9907    None\n",
       "9908    None\n",
       "9909    None\n",
       "9910    None\n",
       "9911    None\n",
       "Length: 9912, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda y: save_image(load_image(\"../data/train/\" + y.Id + \".jpg\", 240, 240, 240), \"../data/train_scaled_padded/\" + y.Id + \".jpg\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517b5a0-68a6-4676-b4d0-439ef6707858",
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot = df.iloc[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce35289-5fc1-43a0-9fbc-6a6903db4d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
